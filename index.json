[{"categories":["History and Taiwan"],"contents":" ##歷史典故：科西拉、科林斯與雅典 在古希臘世界的漫長歷史長河中，有一個關於權力、野心和命運的故事，被記錄在修昔底德的《伯羅奔尼撒戰爭史》中，這個故事猶如一面映照現代國際政治的明鏡。 科西拉，這個位於愛奧尼亞海的小島，原本只是科林斯強大帝國的一個邊陲殖民地。母邦與殖民地之間的關係如同君主與臣服領地，看似穩固，實則暗潮洶湧。科西拉憑藉其得天獨厚的地理位置和日益強大的海軍實力，逐漸萌生了掙脫科林斯控制的野心。 這是一個關於權力平衡的永恒故事。科西拉並非一味盲目反抗，而是在國際政治的棋盤上審慎地計算著每一步。她意識到單憑自身力量難以完全擺脫科林斯的陰影，於是將目光投向了當時正在崛起的雅典。這一戰略聯盟不僅是尋求生存之道，更是一場精心設計的政治算計。 雅典，這個以民主和文明著稱的城邦，並非出於純粹的慈善，而是敏銳地捕捉到了一個牽制科林斯的絕佳機會。兩個城邦的結盟，表面上是保護與被保護的關係，實則是一場複雜的政治角力。雅典的軍事支持不僅是對科西拉的救贖，更是對科林斯實力的一記重擊。 科林斯如何看待這一切？作為一個曾經的霸主，他們視科西拉的背叛如同對尊嚴的赤裸裸侮辱。這種背叛觸及的不僅是領土，更是一個帝國的榮耀與威信。科林斯被迫做出回應，他們明白，縱容科西拉的行為，意味著帝國影響力的削弱。 這場看似局部的衝突，實則埋下了伯羅奔尼撒戰爭的種子。兩個強權——雅典與科林斯，因為一個小島的命運而最終走向全面對抗。這不僅是一場軍事衝突，更是一場關於主權、影響力和國際秩序的根本性較量。 在古希臘的世界中，有一個小島科西拉和一個强大的城邦科林斯之間的故事，彷彿在訴說著當今台灣與中國之間的複雜命運。\n##想像一下 科西拉就像台灣，一個渴望自主卻又備受威脅的小島。她不想被科林斯完全控制，但又無法完全獨立。自1949年以來，台灣一直在這樣的夾縫中求生存，一邊鞏固著自己的民主制度，一邊小心翼翼地平衡著來自強大鄰國的壓力。 科西拉知道自己需要盟友，於是她轉向強大的雅典——就像台灣投向美國的懷抱。這不僅僅是尋求保護，更是一場複雜的戰略遊戲。美國支持台灣，不僅因為關心這個民主社會，更是為了牽制中國在亞太地區不斷擴張的野心。 而科林斯，正如今天的中國，對科西拉的抗爭怒不可遏。在他們眼中，這不僅僅是一個小島的反抗，更是對自身權威的赤裸裸挑釁。中國堅稱台灣是其不可分割的一部分，並且不排除使用武力來\u0026quot;收復\u0026quot;這片土地。 這是一個跨越千年的政治寓言。無論是古希臘的海域，還是現代的台灣海峽，強權與自由、控制與抵抗的鬥爭始終在上演。科西拉的故事告訴我們，小國的命運往往懸而未決，取決於國際局勢的微妙平衡。 台灣就像科西拉，在強權夾縫中堅韌地生存。她不僅在抵抗，更在證明自己存在的價值。無論是經濟、科技還是民主，台灣都在向世界證明：即便是小島，也可以擁有自己的尊嚴和選擇。 這個故事還在繼續，而結局，有待書寫。 2. 歷史上的理性與傲慢：伯羅奔尼撒戰爭與現代戰爭 伯羅奔尼撒戰爭中的理性失敗：\n修昔底德記錄了伯里克利的策略失誤。他認為支持科西拉對抗科林斯可以增強雅典的實力，但卻未預料到斯巴達的參與及長期消耗戰的後果。 伯里克利的推演過於依賴理性設計的“完美計劃”，忽略了人性、情緒和偶然因素，最終引發了雅典的災難。 現代戰爭的平行例子：\n德國在1914年的戰略設計類似雅典的情況。他們預計俄羅斯會保持中立，或者若干替代方案會奏效。但實際上，所有假設都錯誤，並導致第一次世界大戰的爆發。 修昔底德提醒，理性在制定複雜策略時，可能忽視意料之外的情況和人性中的不可預測性，從而引發悲劇。\n我們學習國際關係試圖預測對手的策略，但得到的答案是我們無法預測\n","permalink":"https://s0914712.github.io/blog/post-5/","tags":["Thucydides Trap","history","Trap","Taiwan"],"title":"修昔底德的陷阱(Thucydides Trap)"},{"categories":["AI解決軍事問題"],"contents":" 中共的航母每次出航，海軍的弟兄又得要出去跟監，壓力超大，有沒有辦法預知他的出現呢? 我們蒐集到日本防衛省統合幕僚監部 下載 2023-2024年經過日本的航母動態 整理成csv檔 資料集長得像下面這樣\nDATE Intel BZK battleshi1(\u0026lt;3) battleshi1(\u0026gt;3) carrier WZ7 R_Navy H6 Y-9 Russia Air Warning Taiwan Air Activity Taiwan 1LA Exerise month in 5 Eay inetel in 5 Eay Russiashi1 in 5 Eay battleshi1 in5EayH6Y9 is5datCARRIER 20230101 K K K 1 19 0 1 0 0 1 0 FALSE 20230102 K K K 1 0 0 1 0 0 2 0 TRUE 20230103 1 0 0 1 0 0 4 2 TRUE 20230104 T T 1 3 0 1 0 0 1 0 FALSE 20230105 1 3 0 1 1 0 3 0 FALSE 20230106 1 3 0 1 1 0 3 0 FALSE 試著把各種不同的機種出現都列出來 看機器學習 能不能辦到預測航母的出現 應該用LSTM 來做會比較準確 但實驗性質 我們就把5年內出現與否當作一個參數 使用RrandomForest 或XGBoost 分類法就好 點我下載 資料集說明\ncarrier 是我們想要預測的對象 Intel 情報船 BZK 無人機 battleship 戰艦 R_Navy 俄羅斯海軍 Russia Air俄羅斯空軍 7, Warning 航行警告 發布 Taiwan Air Activity 臺灣地區軍事動態 in 5 Day \u0026hellip; 在五天內是否有出現\u0026hellip;. 開始讀取資料 寫程式 import pandas as pd import numpy as np from sklearn.model_selection import train_test_split from sklearn.preprocessing import LabelEncoder from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score, classification_report data_path=\u0026#39;Japan.csv\u0026#39; def load_and_preprocess_data(data_path): \u0026#34;\u0026#34;\u0026#34; Load and preprocess the data \u0026#34;\u0026#34;\u0026#34; df = pd.read_csv(data_path) # Check for unexpected values in carrier column expected_values = {\u0026#39;K\u0026#39;, \u0026#39;N\u0026#39;, \u0026#39;E\u0026#39;, np.nan} unexpected_values = set(df[\u0026#39;carrier\u0026#39;].unique()) - expected_values if unexpected_values: print(\u0026#34;\\nWarning: Unexpected values found in carrier column:\u0026#34;) print(f\u0026#34;Unexpected values: {unexpected_values}\u0026#34;) print(\u0026#34;\\nRows with unexpected values:\u0026#34;) for value in unexpected_values: unexpected_rows = df[df[\u0026#39;carrier\u0026#39;] == value] print(f\u0026#34;\\nValue \u0026#39;{value}\u0026#39; appears in rows:\u0026#34;) print(unexpected_rows[[\u0026#39;DATE\u0026#39;, \u0026#39;carrier\u0026#39;]].to_string()) df[\u0026#39;carrier\u0026#39;] = df[\u0026#39;carrier\u0026#39;].fillna(\u0026#39;N\u0026#39;) return df def prepare_features(df): \u0026#34;\u0026#34;\u0026#34; Prepare features for the model \u0026#34;\u0026#34;\u0026#34; features = [ \u0026#39;Intel\u0026#39;, \u0026#39;BZK\u0026#39;, \u0026#39;battleship(\u0026lt;3)\u0026#39;, \u0026#39;battleship(\u0026gt;3)\u0026#39;, \u0026#39;WZ7\u0026#39;, \u0026#39;R_Navy\u0026#39;, \u0026#39;H6\u0026#39;, \u0026#39;Y-9\u0026#39;, \u0026#39;Russia Air\u0026#39;, \u0026#39;Warning\u0026#39;, \u0026#39;Taiwan Air Activity\u0026#39;, \u0026#39;Taiwan PLA Exerise\u0026#39;, \u0026#39;month\u0026#39;, \u0026#39;in 5 day intel\u0026#39;, \u0026#39;in 5 day Russiaship\u0026#39;, \u0026#39;in 5 day battleship\u0026#39;, \u0026#39;in5dayH6Y\u0026#39; ] # Verify available features available_features = [f for f in features if f in df.columns] # Data preprocessing for feature in available_features: df[feature] = pd.to_numeric(df[feature], errors=\u0026#39;coerce\u0026#39;).fillna(0) return df[available_features], available_features def train_model(X, y): \u0026#34;\u0026#34;\u0026#34; Train the Random Forest model with handling for small datasets \u0026#34;\u0026#34;\u0026#34; le = LabelEncoder() y_encoded = le.fit_transform(y) # Check class distribution unique_classes, class_counts = np.unique(y_encoded, return_counts=True) min_samples = min(class_counts) if min_samples \u0026lt; 2: print(f\u0026#34;Warning: Very small dataset detected. Using all data for training.\u0026#34;) model = RandomForestClassifier( n_estimators=200, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42 ) model.fit(X, y_encoded) return model, le, (X, y_encoded) else: # Normal split and training if enough samples X_train, X_test, y_train, y_test = train_test_split( X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded ) model = RandomForestClassifier( n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42 ) model.fit(X_train, y_train) return model, le, (X_test, y_test) def evaluate_model(model, X_test, y_test): \u0026#34;\u0026#34;\u0026#34; Evaluate model performance with proper handling of all classes \u0026#34;\u0026#34;\u0026#34; y_pred = model.predict(X_test) print(\u0026#34;\\nModel Evaluation:\u0026#34;) print(f\u0026#34;Accuracy: {accuracy_score(y_test, y_pred):.4f}\u0026#34;) # Get actual unique classes from the data unique_classes = sorted(np.unique(y_test)) # Get class names from label encoder class_names = [\u0026#39;K\u0026#39;, \u0026#39;N\u0026#39;, \u0026#39;E\u0026#39;] # Ensure we have all class names for the report actual_class_names = [class_names[i] for i in unique_classes] print(\u0026#34;\\nClassification Report:\u0026#34;) try: print(classification_report(y_test, y_pred, target_names=actual_class_names)) except Exception as e: print(\u0026#34;Detailed class-wise metrics:\u0026#34;) # Manual calculation of metrics for each class for class_idx, class_name in zip(unique_classes, actual_class_names): class_mask = (y_test == class_idx) class_pred_mask = (y_pred == class_idx) class_correct = np.sum((y_test == y_pred) \u0026amp; class_mask) class_total = np.sum(class_mask) class_precision = np.sum((y_test == y_pred) \u0026amp; class_pred_mask) / (np.sum(class_pred_mask) + 1e-10) class_recall = class_correct / (class_total + 1e-10) class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall + 1e-10) print(f\u0026#34;\\nClass: {class_name}\u0026#34;) print(f\u0026#34;Samples: {class_total}\u0026#34;) print(f\u0026#34;Precision: {class_precision:.4f}\u0026#34;) print(f\u0026#34;Recall: {class_recall:.4f}\u0026#34;) print(f\u0026#34;F1-score: {class_f1:.4f}\u0026#34;) def predict_carrier(model, le, features, new_data): \u0026#34;\u0026#34;\u0026#34; Make prediction for new data \u0026#34;\u0026#34;\u0026#34; df_new = pd.DataFrame([new_data]) for feature in features: if feature not in df_new.columns: df_new[feature] = 0 df_new = df_new[features] pred = model.predict(df_new) prob = model.predict_proba(df_new) return le.inverse_transform(pred)[0], prob[0] if __name__ == \u0026#34;__main__\u0026#34;: data_path = \u0026#34;Japan.csv\u0026#34; try: print(\u0026#34;Loading data from:\u0026#34;, data_path) # Load and preprocess data df = load_and_preprocess_data(data_path) # Prepare features X, features = prepare_features(df) y = df[\u0026#39;carrier\u0026#39;] # Print basic statistics total = len(df) value_counts = y.value_counts() print(\u0026#34;\\nDetailed carrier value counts:\u0026#34;) print(value_counts) print(\u0026#34;\\nBasic Statistics:\u0026#34;) print(f\u0026#34;Total Records: {total}\u0026#34;) # Print counts for each value, including unexpected ones for value in value_counts.index: count = value_counts[value] percentage = count/total print(f\u0026#34;Carrier appearances as \u0026#39;{value}\u0026#39;: {count} ({percentage:.2%})\u0026#34;) # Train model model, label_encoder, (X_test, y_test) = train_model(X, y) # Evaluate model evaluate_model(model, X_test, y_test) # Feature importance importance = pd.DataFrame({ \u0026#39;feature\u0026#39;: features, \u0026#39;importance\u0026#39;: model.feature_importances_ }).sort_values(\u0026#39;importance\u0026#39;, ascending=False) print(\u0026#34;\\nFeature Importance:\u0026#34;) print(importance) # Example prediction(這邊給一個樣本讓他預測) new_data = {f: 0 for f in features} new_data.update({ \u0026#39;R_Navy\u0026#39;: 1, \u0026#39;month\u0026#39;: 1, \u0026#39;in 5 day Russiaship\u0026#39;: 1 }) prediction, probabilities = predict_carrier(model, label_encoder, features, new_data) print(\u0026#34;\\nPrediction Results:\u0026#34;) print(f\u0026#34;Predicted Location: {prediction}\u0026#34;) # Print probabilities for all classes class_names = label_encoder.classes_ # Use actual classes from encoder for class_name, prob in zip(class_names, probabilities): print(f\u0026#34;Probability of {class_name}: {prob:.2%}\u0026#34;) except FileNotFoundError: print(f\u0026#34;Error: File \u0026#39;{data_path}\u0026#39; not found\u0026#34;) except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) 以下是程式的結果 Loading data from: Japan.csv Detailed carrier value counts: carrier N 617 K 113 Name: count, dtype: int64 Basic Statistics: Total Records: 730 Carrier appearances as \u0026#39;N\u0026#39;: 617 (84.52%) 沒出現航母的樣本數 Carrier appearances as \u0026#39;K\u0026#39;: 113 (15.48%) 出現航母的樣本數 模型的評估 Model Evaluation: Accuracy: 0.9863 Classification Report: precision recall f1-score support 預測航母出現的準確率 K 0.96 0.96 0.96 23 預測航母沒出現的準確率 N 0.99 0.99 0.99 123 accuracy 0.99 146 macro avg 0.97 0.97 0.97 146 weighted avg 0.99 0.99 0.99 146 #recall 為預測為正的數量(有可能沒出現也給他預測出現) Feature Importance: feature importance 10 is5datCARRIER 0.893500 9 month 0.059949 8 Taiwan Air Activity 0.036262 7 Warning 0.010289 0 Intel 0.000000 1 BZK 0.000000 2 WZ7 0.000000 3 R_Navy 0.000000 4 H6 0.000000 5 Y-9 0.000000 6 Russia Air 0.000000 給予的樣本預測 Prediction Results: Predicted Location: N Probability of K: 0.05% Probability of N: 99.95% 結論 我們可以看到分類的狀況還蠻好的，但是航母出現的資料數量其實蠻少的，就算全部猜不出現，也能猜對85%，我們看分類出來 第一個是看前五天有沒有出現，再來按照月份、再來是臺灣地區空中動態與航行警告的發布，因此可以知道這幾個因素有相關聯 2023至2024年11月份，航母活動在西太平洋區域而被日方偵測到的天數有113天，未出現的天數為617天，運用機器學習的分類技巧可以預測航母未出現的機率，我們可以觀察到AI在判斷是否有航母出現時首先先檢查前一天是否有航母出現，其次是月份(共軍航母在2023年至2024年通常於9-10月出現比例較大)還有臺灣地區的共機動態(如圖)、航行警告的發布等等都可以作為預判航母出航的徵兆，因此在機器學習技術成熟的今日，在探索軍事動態相關因素上吾人更應該廣泛地蒐集可能原因，然後藉由分析技術預測。\n不過這個模型也只能掌握了某些邏輯，無法100%預測 ","permalink":"https://s0914712.github.io/blog/post-4/","tags":["AI","Military","PLA","軍事動態","航母","深度學習"],"title":"使用機器學習 預測軍事動態-航母篇"},{"categories":["AI解決軍事問題"],"contents":" 使用MLP分析臺海周邊海、空域動態 數據處理在現代資訊系統中至關重要。有效的數據處理能幫助組織從大量數據中提取出有價值的資訊，為後續的決策提供基礎。同時，良好的數據清理、轉換與整合過程能降低錯誤率，增加模型的可靠性。特別是在軍事、金融等高風險領域，數據處理的精確性直接影響任務成敗，以下就數據的清理流程與研究方法進行介紹。\n數據處理 國防部網站上有109年至113年每天的中共解放軍臺海周邊海、空域動態，雖然經過模糊化，但裡面每天出現的機種類型和區域已足夠進行分類和推理，經過資料的整理，統計出大約有20種機型，每天有不一樣的活動動態(如表一)，每一行代表一個時間點的軍事設備部署情況。對於每一行數據，程序創建一個圖，其中節點代表不同類型的軍事設備（如戰鬥機、轟炸機等），節點的值表示該設備的活動的區域代號。我們把它整理成CSV文件，藉由pandas的dataframe函式庫進行分析。\nDATE J10 J11 J16 Y9EW Y8EW Y8ELINT Y8ASW Y8REC Y20 BZK WZ7 Z9 Y9CC SU30 H6 JH7 TB001 CH4 GJ2 KJ500 0601 2 0 0 0 0 0 0 0 0 0 3 0 0 2 0 0 0 0 0 0 0602 0 0 0 0 0 0 0 0 0 0 3 3 0 2 0 0 0 0 0 0 表一：整理後的資料集的一部分\n多層次感知演算法 因為除了空警500外一共有19種機型，並且我們需要知道的是「是否會出現空警500」這個1個答案，因此建立三個輸入層為19個神經節點(用來輸入除空警500外的19種機型出現況況)、隱藏層為3個節點(用來給神經網路交叉比對)，輸出層為1個節點(用來輸出空警500出現機率)的類神經網路， 並定義神經網路間傳遞的方式若數值小於0歸零，數值大於0則為線性之激勵函式（activation function），經過將誤差函數微分並且求極小值的過程後，我們的模型準確度在8成。 如果我們發現某個機型(如轟六)與空警500的關係密切，出現轟六往往會出現空警500，那麼顯示在轟六的權重便會比其他機型高出許多。 初次推理後結果並不如我們預期，因此需要檢討相關變數以提升模型的準確率。\n因此我們嘗試將美艦通過與議員訪臺事件加入分析。 共軍執行任務的理由可能為了例行訓練、演習、或是運用軍事力量威嚇踏入範圍的敵對勢力，例行的訓練或演習很容易有規律的週期，但若是威嚇敵對勢力這種突發事件就沒有所謂的週期，因次我們把歷史上的變因(議員訪臺以及美艦通過臺海)加入模型內，藉以提升模型的準確性。經過增加變數，模型的準確度增加為85.92%。\n組合一 殲10、殲11、運9、運8、BZK無人機、直九直升機、轟六 組合二 殲10、BZK無人機、運9CC、TB001無人機 組合三 排除只出現運8、運8反潛機、運20、彩虹無人機 表二：三種藉由權重分析空警500出現時的搭配機種組合\n使用圖神經網路分析 節點分類 試著試著使用圖神經網路結構來提升訓練 ，首先將資料集內的特徵進行分類，分成無人機(TB001, CH4,GJ2,WZ7, BZK)、戰鬥機(J10,J11,J16,SU30)、偵查任務機(Y9EW, Y8EW,Y8ELINT,Y8ASW, Y8REC,Z9)、以支援機種 (Y20,Y9CC) , C2(KJ500)，其中無人機與偵察任務機擔任集群，保障集群由Y20,Y9CC擔任，突擊集群由H6, JH7擔任，KJ-500擔任指管中心，戰鬥機可能擔任掩護集群以及保障集群之中。\n圖的連接規則： 把圖的連接遵循上述的規則，表示彼此的關係(如圖三)：\nKJ500（預警機）與所有其他節點相連，表示其為指揮中心。 戰鬥機組（J10, J11, J16, SU30）和偵察任務飛機組（Y9EW, Y8ELINT, Y8ASW, Y8REC）只與中心節點（KJ500, H6, JH7, Y20, Y9CC）相連，因偵察任務機組負責提供關鍵資訊給屬於指揮或打擊的機組。 無人機與直升機組（BZK, WZ7, Z9, CH4, TB001）也只與中心節點相連，無人機與直升機負責提供。 中心節點之間互相連接。 如果兩個機種出現的區域類似，也會建立連接。 建立網路模型 有了基本的圖神經網路結構後，我們使用PyTorch Geometric庫實現GNN模型。模型包含兩層圖卷積層（GCNConv）和一個全連接層。模型的輸入是圖的節點特徵和邊的訊息，輸出是一個二元分類（預測KJ500是否出現）。後續再將模型使用Adam優化器進行訓練，計算損失後再進行反向傳播直到損失無法下降為止。\n模型評估：評估指標包括準確率、AUC（曲線下面積）和平均交叉熵。這些指標全面反映了模型的分類性能和預測的確定性。我們定義準確率為： 第一張圖顯示 ROC 曲線（接收者操作特徵曲線），AUC（曲線下的面積）為 1.0，表明模型的分類能力非常好，能夠完美區分正負類別。ROC 曲線越靠近左上角，AUC 越接近 1，說明模型性能越優異。此曲線用於衡量模型的靈敏度與特異度的平衡。 第二張圖是混淆矩陣，用於展示分類結果。圖中顯示模型在 68 個負類別樣本中正確預測了 68 個，有 1 個負類別樣本被錯誤預測為正類別。對於正類別樣本，模型正確預測了 2 個。\n圖:ROC 曲線（接收者操作特徵曲線）\n圖:AUC\n為了比較使用圖神經網路與多層次感知演算法的效能，其中圖神經網路 (GNN) 的準確率最高，達到 0.9859，這意味著它能夠較為準確地預測樣本，而GNN 的 AUC 為 1.0000，這表明它在不同的分類下均有很好的區分能力，具有的平均交叉熵也最低，僅為 0.0654，表明它的預測不確定性最小，並且預測結果更接近真實值，根據這些數據，圖神經網路 (GNN) 在準確率、AUC 和平均交叉熵上均優於多層次感知演算法，顯示出它在此任務上的強大表現。\n模型 圖神經網路 多層次感知 準確率(Accuracy) 98.59% 85.92% 曲線下面積(AUC) 1.0000 0.7681 平均交叉熵(Cross-Entropy) 0.0785 0.3474 表三:準確率 使用「Prophet」預測戰備警巡與西南空域活動 像部隊活動這種多半具有週期性，我們可以結合上述的資料集每天的活動數量與戰備警巡的日期進行進一步的分析，戰備警巡為中共東部戰區位臺灣周邊海空域進行之例行性海空兵力聯合巡邏活動，在戰備警巡實施期間，我們可以由發布的新聞稿中觀察到中共軍機和船艦的活動大幅增加，機型種類也更加完整，中共發言人在例行記者會解釋：「戰備警巡主要目的在進一步提升部隊實戰化訓練水平，增強捍衛國家主權和領土完整的打仗能力，共軍將持續練兵備戰，繼續常態組織有關軍事行動」，而戰備警巡發生的時間往往都在晚上或是清晨，雖然只在我24浬處進行，但軍事行動已具備「猝然攻擊」的戰術戰法，使我國軍最前線海空人員疲於奔命，藉由統計戰備警巡新聞報導的資料，可以大致推估戰備警巡週期大月在6-14天不等，但這僅是藉由統計資料直觀判斷的結果，如果加上深度學習工具，我們更能做到「預測」，我們可以運用由 Facebook 核心科學資料小組。(Facebook Core Data Science Team )發表的「Prophet」程式庫，進行時間序列預測， 「Prophet」程式庫主要是綜合趨勢、季節性、假日或特殊事件等資訊進行預測，被廣泛運用股市或是銷售量預測，經由這套工具分析戰備警巡與時間週期的關係我們可以得到以下結論。 (一)戰備警巡執行週期約在6-14天，發生時間以周三到周五頻率為最高，週六為發生頻率較低的時間： 這也與我們觀察的數據一致，藉由系統得出的執行週期，可推測未來20天哪幾天共軍執行戰備警巡的機率較高(如圖六)。 (二)結合戰備警巡的時間可以提升預測空警500機率的準確度： 我們假設空警500的出現與戰備警巡有很大的關聯性，因此可以將戰備警巡的因素加入評估，可以藉由「Prophet」這套工具來進行分析， 經過分析後可以得知戰備警巡與美艦通過臺海對於空警500的出現有顯著的影響，幾乎每一次中共空軍戰備警巡都會出現空警500，因此若是加入戰備警巡時間與其他機種出現次數作為變量，空警500預測準確度可得到進一步提升(如圖六)\n###運用「Prophet」程式庫預測戰備警巡時間圖\n結論與未來展望 1.研究成果總結本研究透過深度學習技術，成功建立了預測共機活動的模型系統，取得以下具體成果： 建立了具有80%以上準確度的空警500預測模型，能夠根據其他機型組合預測空警500出現機率。 發現特定機型組合(如殲10、殲11、運8電戰、BZK等)與空警500的高度關聯性，並歸納出三種主要的空中編組模式。 運用Prophet工具成功預測戰備警巡週期(6-14天)，並發現其與空警500出現有顯著相關性。 透過區域活動分析，揭示當空警500出現時，其他機型(如運八電偵機、無偵七、轟六)會減少西南部活動而增加東部活動的趨勢。 2 .中共空中作戰訓練模式反映了其明確的戰略布局。在西南空域的平時演練與演訓中，空中預警機擔任前線指揮中心，電偵機和警戒機作為先遣部隊，為後方轟六轟炸機的攻擊行動提供掩護，而圖神經網路技術則為我們提供這些空中陣形的可能性。習近平提出的「實戰化訓練」亦即「理念仗在哪裡打，兵就在哪裡練」。海空聯合遠程飛行訓練正是這一戰略思維的具體實踐。從訓練方式和目標來看，美軍可能是其主要假想敵，而臺灣的西南空域則是其練兵場所。東部戰區與南部站區於此空域部署同等規模兵力進行區域接力監視，空警500(KJ-500)則扮演中繼與指揮的角色。\n","permalink":"https://s0914712.github.io/blog/post-1/","tags":["AI","Military","PLA","軍事動態","軍演","深度學習"],"title":"使用MLP分析臺海周邊海、空域動態"},{"categories":["AI解決軍事問題"],"contents":" 認識 Prophet Prophet 是一個由 Facebook Core Data Science Team 發表的開源代碼庫，用於時間序列預測，基於 Python 和 R 語言。相較於自行訓練時間序列預測模型，Prophet 的一些優點如下：‌\n改善模型選擇和調參的時間成本：時間序列有許多經典算法如 AR, VAR, ARMA, ARIMA, 指數平滑法等，選擇模型和調參的過程可被自動化。 提供讓分析師、領域專家能根據經驗法則設定的參數：例如歷史週期、特殊節日的日期等，不會因為寫成制式套件就失去自己手刻的好處。\n安裝步驟 (0) 首先建議要用 conda 創建虛擬環境，避免不同套件版本產生不必要的衝突\n(base) $ conda create -n env_name python=3.7 (base) $ conda activate env_name (env_name) $ Windows 而 Windows 的預設編譯器是 MSVC ，pystan 並不支援，因此需要額外安裝 Windows 版本的 gcc：mingw-w64 compiler\n(env_name) $ conda install libpython m2w64-toolchain -c msys2 確認都有安裝好支援的 c++ compiler 後，記得先安裝 pystan 。以下都建議使用 conda install，不要用 pip install，虛擬環境下的 jupyter notebook 可能會 import 不到。\n(env_name) $ conda install -c pystan conda-forge 接著安裝 prophet （注意：v1.0 後的版本套件名稱為 prophet，不再是 fbprophet，網路上很多教學文章還以舊稱，記得在 import 時調整即可\n(env_name) $ conda install -c prophet conda-forge ###完成好以後就可以載入資料集進行分析\n像部隊活動這種多半具有週期性，我們可以結合上述的資料集每天的活動數量與戰備警巡的日期進行進一步的分析，戰備警巡為中共東部戰區位臺灣周邊海空域進行之例行性海空兵力聯合巡邏活動，在戰備警巡實施期間，我們可以由發布的新聞稿中觀察到中共軍機和船艦的活動大幅增加，機型種類也更加完整，中共發言人在例行記者會解釋： 「戰備警巡主要目的在進一步提升部隊實戰化訓練水平，增強捍衛國家主權和領土完整的打仗能力，共軍將持續練兵備戰，繼續常態組織有關軍事行動」\n，而戰備警巡發生的時間往往都在晚上或是清晨，雖然只在我24浬處進行，但軍事行動已具備「猝然攻擊」的戰術戰法，使我國軍最前線海空人員疲於奔命，藉由統計戰備警巡新聞報導的資料，可以大致推估戰備警巡週期大月在6-14天不等，但這僅是藉由統計資料直觀判斷的結果，如果加上深度學習工具，我們更能做到「預測」，「Prophet」程式庫，進行時間序列預測\n# 將 day.csv 匯入資料框 # 由 parse_dates 指定代表日期的行 df = pd.read_csv(\u0026#39;day.csv\u0026#39;, parse_dates=[1]) df2 = pd.read_csv(\u0026#39;/content/dateAndcharacter.csv\u0026#39;,parse_dates=[1]) DF_PLANE = pd.DataFrame(df2) DF_PLANE[\u0026#39;DATE\u0026#39;] = pd.to_datetime(DF_PLANE[\u0026#39;DATE\u0026#39;], format=\u0026#39;%Y%m%d\u0026#39;) DF_PLANE 以上的資料集為2023年國防部軍事動態網站上擷取出來的公開資料 我把它彙整成csv檔案 連結在這裡 2023年國防部軍事動態網站軍事動態彙整\n接下來就開始 開工寫程式 載入資料集 df2 = df.copy() DF_PLANE2=DF_PLANE.copy() DF_PLANE2=DF_PLANE2[[\u0026#39;DATE\u0026#39;, \u0026#39;KJ-500\u0026#39;]] #把想要評估的對象設定為y 這邊以KJ-500 DF_PLANE2.columns = [\u0026#39;ds\u0026#39;, \u0026#39;y\u0026#39;] # 設定分割日 mday mday = pd.to_datetime(\u0026#39;2023-10-1\u0026#39;) # 建立訓練用 index 與驗證用 index train_index = DF_PLANE2[\u0026#39;ds\u0026#39;] \u0026lt; mday test_index = DF_PLANE2[\u0026#39;ds\u0026#39;] \u0026gt;= mday # 分割輸入資料 x_train = DF_PLANE2[train_index] x_test = DF_PLANE2[test_index] # 分割日期資料（用於繪製圖形） dates_test = DF_PLANE2[\u0026#39;ds\u0026#39;][test_index] 選擇prophet演算法 from prophet import Prophet # 選擇模型 # 這 3 個 seasonality 參數的設定很重要 # 本資料為日單位，因此不需使用 daily_seasonality # weekly_seasonality 與 daily_seasonality 除了 True/False 以外， # 也可以指定成數值（三角函數的數量） # seasonality_mode: additive(預設) multiplicative m1 = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True,interval_width=0.9, seasonality_mode=\u0026#39;multiplicative\u0026#39;) 訓練與預測 m1.fit(x_train) future1 = m1.make_future_dataframe(periods=61, freq=\u0026#39;D\u0026#39;) 確認結果 display(future1.head()) display(future1.tail()) fcst1 = m1.predict(future1) fig = m1.plot_components(fcst1) plt.show() 繪製圖形 計算與實際的差異值(R2) # 只從 fcst2 中提取預測部分 ypred2 = fcst2[-88:][[\u0026#39;yhat\u0026#39;]].values # 計算 R2 值 score2 = r2_score(ytest1, ypred2) #### 確認結果 r2_text2 = f\u0026#39;R2 score:{score2:.4f}\u0026#39; print(r2_text2) 繪製時間序列圖 import matplotlib.dates as mdates fig, ax = plt.subplots(figsize=(8, 4)) #### 繪製圖形 ax.plot(dates_test, ytest1, label=\u0026#39;標準答案\u0026#39;, c=\u0026#39;k\u0026#39;) ax.plot(dates_test, ypred1, label=\u0026#39;預測結果 v1\u0026#39;, c=\u0026#39;c\u0026#39;) ax.plot(dates_test, ypred2, label=\u0026#39;預測結果 v2\u0026#39;, c=\u0026#39;b\u0026#39;) # 日期刻度間隔 # 於每週四顯示日期 weeks = mdates.WeekdayLocator(byweekday=mdates.TH) ax.xaxis.set_major_locator(weeks) #### 將日期刻度標籤文字旋轉 90 度 ax.tick_params(axis=\u0026#39;x\u0026#39;, rotation=90) #### 開始日與結束日 sday = pd.to_datetime(\u0026#39;2023-10-1\u0026#39;) eday = pd.to_datetime(\u0026#39;2023-12-31\u0026#39;) ax.set_xlim(sday, eday) #### 顯示網格等 ax.grid() ax.legend() ax.set_title(\u0026#39;KJ-500 出現機率預測結果 \u0026#39; + r2_text2) 輸出畫面 結論 經由這套工具分析戰備警巡與時間週期的關係我們可以得到以下結論。 (一)戰備警巡執行週期約在6-14天，發生時間以周三到周五頻率為最高，週六為發生頻率較低的時間： 這也與我們觀察的數據一致，藉由系統得出的執行週期，可推測未來20天哪幾天共軍執行戰備警巡的機率較高\n","permalink":"https://s0914712.github.io/blog/post-3/","tags":["AI","Military","PLA","軍事動態","軍演","深度學習"],"title":"使用機器學習 預測軍事動態-西南空域篇"},{"categories":["HTML \u0026 CSS"],"contents":"Emphasis 認識 Prophet Prophet 是一個由 Facebook Core Data Science Team 發表的開源代碼庫，用於時間序列預測，基於 Python 和 R 語言。相較於自行訓練時間序列預測模型，Prophet 的一些優點如下：‌\n改善模型選擇和調參的時間成本：時間序列有許多經典算法如 AR, VAR, ARMA, ARIMA, 指數平滑法等，選擇模型和調參的過程可被自動化。 提供讓分析師、領域專家能根據經驗法則設定的參數：例如歷史週期、特殊節日的日期等，不會因為寫成制式套件就失去自己手刻的好處。\n安裝步驟 (0) 首先建議要用 conda 創建虛擬環境，避免不同套件版本產生不必要的衝突\n(base) $ conda create -n env_name python=3.7 (base) $ conda activate env_name (env_name) $ Windows 而 Windows 的預設編譯器是 MSVC ，pystan 並不支援，因此需要額外安裝 Windows 版本的 gcc：mingw-w64 compiler\n(env_name) $ conda install libpython m2w64-toolchain -c msys2 確認都有安裝好支援的 c++ compiler 後，記得先安裝 pystan 。以下都建議使用 conda install，不要用 pip install，虛擬環境下的 jupyter notebook 可能會 import 不到。\n(env_name) $ conda install -c pystan conda-forge 接著安裝 prophet （注意：v1.0 後的版本套件名稱為 prophet，不再是 fbprophet，網路上很多教學文章還以舊稱，記得在 import 時調整即可\n(env_name) $ conda install -c prophet conda-forge 完成好以後就可以載入資料集進行分析 像部隊活動這種多半具有週期性，我們可以結合上述的資料集每天的活動數量與戰備警巡的日期進行進一步的分析，戰備警巡為中共東部戰區位臺灣周邊海空域進行之例行性海空兵力聯合巡邏活動，在戰備警巡實施期間，我們可以由發布的新聞稿中觀察到中共軍機和船艦的活動大幅增加，機型種類也更加完整，中共發言人在例行記者會解釋：「戰備警巡主要目的在進一步提升部隊實戰化訓練水平，增強捍衛國家主權和領土完整的打仗能力，共軍將持續練兵備戰，繼續常態組織有關軍事行動」，而戰備警巡發生的時間往往都在晚上或是清晨，雖然只在我24浬處進行，但軍事行動已具備「猝然攻擊」的戰術戰法，使我國軍最前線海空人員疲於奔命，藉由統計戰備警巡新聞報導的資料，可以大致推估戰備警巡週期大月在6-14天不等，但這僅是藉由統計資料直觀判斷的結果，如果加上深度學習工具，我們更能做到「預測」，「Prophet」程式庫，進行時間序列預測\n# 將 day.csv 匯入資料框 # 由 parse_dates 指定代表日期的行 df = pd.read_csv(\u0026#39;day.csv\u0026#39;, parse_dates=[1]) df2 = pd.read_csv(\u0026#39;/content/dateAndcharacter.csv\u0026#39;,parse_dates=[1]) DF_PLANE = pd.DataFrame(df2) DF_PLANE[\u0026#39;DATE\u0026#39;] = pd.to_datetime(DF_PLANE[\u0026#39;DATE\u0026#39;], format=\u0026#39;%Y%m%d\u0026#39;) DF_PLANE df2 = df.copy() DF_PLANE2=DF_PLANE.copy() DF_PLANE2=DF_PLANE2[[\u0026#39;DATE\u0026#39;, \u0026#39;KJ-500\u0026#39;]] #把想要評估的對象設定為y 這邊以KJ-500 DF_PLANE2.columns = [\u0026#39;ds\u0026#39;, \u0026#39;y\u0026#39;] # 設定分割日 mday mday = pd.to_datetime(\u0026#39;2023-10-1\u0026#39;) # 建立訓練用 index 與驗證用 index train_index = DF_PLANE2[\u0026#39;ds\u0026#39;] \u0026lt; mday test_index = DF_PLANE2[\u0026#39;ds\u0026#39;] \u0026gt;= mday # 分割輸入資料 x_train = DF_PLANE2[train_index] x_test = DF_PLANE2[test_index] # 分割日期資料（用於繪製圖形） dates_test = DF_PLANE2[\u0026#39;ds\u0026#39;][test_index] ##選擇演算法\nfrom prophet import Prophet # 選擇模型 # 這 3 個 seasonality 參數的設定很重要 # 本資料為日單位，因此不需使用 daily_seasonality # weekly_seasonality 與 daily_seasonality 除了 True/False 以外， # 也可以指定成數值（三角函數的數量） # seasonality_mode: additive(預設) multiplicative m1 = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True,interval_width=0.9, seasonality_mode=\u0026#39;multiplicative\u0026#39;) ##訓練與預測\nm1.fit(x_train) future1 = m1.make_future_dataframe(periods=61, freq=\u0026#39;D\u0026#39;) 確認結果 display(future1.head()) display(future1.tail()) fcst1 = m1.predict(future1) fig = m1.plot_components(fcst1) plt.show() #繪製圖形\n計算與實際的差異值(R2) # 只從 fcst2 中提取預測部分 ypred2 = fcst2[-88:][[\u0026#39;yhat\u0026#39;]].values # 計算 R2 值 score2 = r2_score(ytest1, ypred2) # 確認結果 r2_text2 = f\u0026#39;R2 score:{score2:.4f}\u0026#39; print(r2_text2) 繪製時間序列圖 import matplotlib.dates as mdates fig, ax = plt.subplots(figsize=(8, 4)) # 繪製圖形 ax.plot(dates_test, ytest1, label=\u0026#39;標準答案\u0026#39;, c=\u0026#39;k\u0026#39;) ax.plot(dates_test, ypred1, label=\u0026#39;預測結果 v1\u0026#39;, c=\u0026#39;c\u0026#39;) ax.plot(dates_test, ypred2, label=\u0026#39;預測結果 v2\u0026#39;, c=\u0026#39;b\u0026#39;) # 日期刻度間隔 # 於每週四顯示日期 weeks = mdates.WeekdayLocator(byweekday=mdates.TH) ax.xaxis.set_major_locator(weeks) # 將日期刻度標籤文字旋轉 90 度 ax.tick_params(axis=\u0026#39;x\u0026#39;, rotation=90) # 開始日與結束日 sday = pd.to_datetime(\u0026#39;2023-10-1\u0026#39;) eday = pd.to_datetime(\u0026#39;2023-12-31\u0026#39;) ax.set_xlim(sday, eday) # 顯示網格等 ax.grid() ax.legend() ax.set_title(\u0026#39;KJ-500 出現機率預測結果 \u0026#39; + r2_text2) 輸出畫面 ","permalink":"https://s0914712.github.io/blog/post-2/","tags":["Ai解決軍事問題","Game","React","Python","New"],"title":"使用Prophet 預測週期方法"}]