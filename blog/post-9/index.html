<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8">
  <title>chen blog s091sdaf</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="this is meta description">
  <meta name="author" content="Jeremy Chen">
    
  
  <meta name="theme-name" content="liva-hugo" />
  
  <meta name="generator" content="Hugo 0.139.3">

  <!-- plugins -->
  
  <link rel="stylesheet" href="https://s0914712.github.io/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="https://s0914712.github.io/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="https://s0914712.github.io/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="https://s0914712.github.io/plugins/venobox/venobox.css ">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="https://s0914712.github.io/scss/style.min.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="https://s0914712.github.io/images/favicon.png " type="image/x-icon">
  <link rel="icon" href="https://s0914712.github.io/images/favicon.png " type="image/x-icon">


<script async src="https://www.googletagmanager.com/gtag/js?id=G-XFZRBQ7BCN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XFZRBQ7BCN');
</script>



</head>
<body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0">
      <a class="navbar-brand mobile-view" href="https://s0914712.github.io/"><img class="img-fluid"
          src="https://s0914712.github.io/images/logo.jpg" alt="chen blog s091sdaf"></a>
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="#"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="#"><i class="ti-twitter-alt"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="#"><i class="ti-instagram"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="#"><i class="ti-github"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="#"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <a class="navbar-brand mx-auto desktop-view" href="https://s0914712.github.io/"><img class="img-fluid"
            src="https://s0914712.github.io/images/logo.jpg" alt="chen blog s091sdaf"></a>

        <ul class="navbar-nav">
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://s0914712.github.io/about/">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://s0914712.github.io/blog/">Post</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://s0914712.github.io/contact/">Contact</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search pl-lg-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://s0914712.github.io//search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/ai%e8%a7%a3%e6%b1%ba%e8%bb%8d%e4%ba%8b%e5%95%8f%e9%a1%8c"
          class="text-primary">Ai解決軍事問題</a>
        
        <h2>只靠每天的架次數預測的Prophet與LSTM 模型</h2>
        <div class="mb-3 post-meta">
          <span>By Jeremy Chen</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>01 December 2024</span>
          
        </div>
        
        <img src="https://s0914712.github.io/images/post/lSTM.jpg" class="img-fluid w-100 mb-4" alt="只靠每天的架次數預測的Prophet與LSTM 模型">
        
        <div class="content mb-5">
          <!-- raw HTML omitted -->
<p>長短期記憶神經網路</p>
<p>當我們在理解一件事情的時候，通常不會每次都從頭開始學習，而是透過既有的知識與記憶來理解當下遇到的問題；事件的發生通常具有連續性，也就是一連串的因果關係，或是一個持續不斷變動的結果。在機器學習模型的發展中，引入這種遞歸 (recurrent) 的概念，是遞歸神經網路與其他神經網路模型 (如 CNN) 相比，較為創新的地方。長短期記憶模型則是改善了遞歸神經網路在長期記憶上的一些不足，因為其強大的辨識能力，可以有效的對上下文產生連結，現在已大量運用在自然語言理解 (例如語音轉文字，翻譯，產生手寫文字)，圖像與影像辨識等應用。
在這邊我先不介紹LSTM的原理，因為這個專案並不是企圖改進LSTM的架構，大家只要知道他是具有理解時間關係的網路結構就可以了，既然prophet 和LSTM 都可以進行時間序列的處理 那我們就使用這兩個做個比較。</p>
<h4 id="meta-prophet-簡介重點在於如何處理時間">Meta Prophet 簡介：重點在於如何處理時間</h4>
<p>Meta Prophet（全名：<strong>Facebook Prophet</strong>）是一款專門用於<strong>時間序列預測</strong>的開源工具，由 Facebook（Meta）開發。它以 Python 和 R 實作，設計目標是讓<strong>非專業統計人員</strong>也能輕鬆處理帶有季節性與節慶效應的時間序列數據。Prophet 被廣泛應用在營收、網站流量、銷售、需求等數據預測領域。</p>
<hr>
<h4 id="prophet-的核心概念與架構">Prophet 的核心概念與架構</h4>
<p>Prophet 將時間序列建模公式拆成三大部分：
[
y(t) = g(t) + s(t) + h(t) + \epsilon_t
]</p>
<ul>
<li><strong>g(t)</strong>：trend（趨勢）</li>
<li><strong>s(t)</strong>：seasonality（季節性成分）</li>
<li><strong>h(t)</strong>：holidays（節日或特殊事件）</li>
<li><strong>ε</strong>：雜訊</li>
</ul>
<hr>
<h4 id="prophet-處理時間的關鍵特點">Prophet 處理時間的關鍵特點</h4>
<ol>
<li>自動識別「時間」欄位</li>
</ol>
<p>Prophet 要求資料有兩個欄位：</p>
<ul>
<li><code>ds</code>（datestamp，日期/時間）</li>
<li><code>y</code>（數值）</li>
</ul>
<p>它會自動將 <code>ds</code> 欄位辨識為<strong>時間軸</strong>，並用它進行所有的分解與運算。</p>
<ol start="2">
<li>趨勢（Trend）建模</li>
</ol>
<p>Prophet 支持兩種主要趨勢建模方式：</p>
<ul>
<li><strong>線性趨勢</strong>（可設定 changepoints 轉折點）</li>
<li><strong>logistic 增長</strong>（適合有上限的數據，如市場飽和）</li>
</ul>
<p>Prophet 會在時間軸上自動尋找可能出現轉折（changepoints）的時刻，允許趨勢在不同時期改變成長率。
3. 週期/季節性（Seasonality）</p>
<p>Prophet 會自動加入<strong>年、週、日</strong>等週期性成分，透過傅立葉級數進行建模。你可以手動新增更多週期（如每月），或調整週期的強度。</p>
<ol start="4">
<li>節日/事件</li>
</ol>
<p>你可以自訂「節日」時間清單（如農曆年、雙 11 等），Prophet 會自動在這些時間點上套用額外的預測效果（如特定天數的異常波動）。</p>
<ol start="5">
<li>處理缺漏值與不規則間距</li>
</ol>
<p>Prophet 可直接處理<strong>缺漏資料</strong>與<strong>不等間隔</strong>的時間序列，不需手動補齊時間軸。</p>
<ol start="6">
<li>時間格式彈性</li>
</ol>
<p>支援多種時間格式（日期、日期時間、timestamp），Prophet 會自動解析。</p>
<ol start="7">
<li>可擴展未來的時間軸</li>
</ol>
<p>你只需告訴 Prophet 要預測幾天/幾週/幾個月後的數值，它會自動根據 trend 和 seasonality 外推時間序列。</p>
<hr>
<h4 id="prophet-處理時間序列的步驟python-範例">Prophet 處理時間序列的步驟（Python 範例）</h4>
<pre tabindex="0"><code>import pandas as pd
from prophet import Prophet

# 資料格式要求
# df 必須包含兩個欄位：ds（日期），y（數值）
df = pd.DataFrame({
    &#39;ds&#39;: pd.date_range(&#39;2023-01-01&#39;, periods=100),
    &#39;y&#39;: [ ... ]  # 你的數值
})

# 建立模型
m = Prophet()
m.fit(df)

# 預測未來 30 天
future = m.make_future_dataframe(periods=30)
forecast = m.predict(future)

# 繪圖
fig = m.plot(forecast)
</code></pre><hr>
<h4 id="prophet-vs-lstm時間處理方式比較總結">Prophet vs. LSTM：時間處理方式比較總結</h4>
<table>
  <thead>
      <tr>
          <th>處理特點</th>
          <th><strong>Prophet</strong></th>
          <th><strong>LSTM</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>1. 時間格式解析</strong></td>
          <td>自動辨識 <code>ds</code> 欄位的時間格式（日期、datetime、timestamp 等）</td>
          <td>時間需手動轉換為連續數值或標準化後的時間特徵</td>
      </tr>
      <tr>
          <td><strong>2. 趨勢、季節性建模</strong></td>
          <td>內建趨勢與多重季節性建模邏輯（如年、週、日）<!-- raw HTML omitted -->可外加節日等事件效應</td>
          <td>不會自動建模趨勢與季節性，需透過大量訓練數據學出時間模式</td>
      </tr>
      <tr>
          <td><strong>3. 缺漏資料處理</strong></td>
          <td>可直接處理不連續與缺漏資料，不需補齊時間軸</td>
          <td>缺值需事先補齊，並要求固定間距的時間序列輸入</td>
      </tr>
      <tr>
          <td><strong>4. 未來預測方式</strong></td>
          <td>明確定義未來時間點，自動產生未來時間序列並套用模型外推</td>
          <td>需遞迴地逐步預測下一時間點，常使用前一步預測作為下一步輸入</td>
      </tr>
      <tr>
          <td><strong>5. 時間粒度調整</strong></td>
          <td>可輕鬆切換日、週、月等粒度</td>
          <td>時間粒度需在特徵工程階段預先設計</td>
      </tr>
      <tr>
          <td><strong>6. 複雜性與需求</strong></td>
          <td>適合小資料量、具明顯週期性與事件驅動的商業場景</td>
          <td>適合大量數據、複雜長期依賴問題（如語音、股價等非週期性應用）</td>
      </tr>
      <tr>
          <td><img src="../../images/post/LSTM.png" alt="image"></td>
          <td></td>
          <td></td>
      </tr>
      <tr>
          <td><img src="../../images/post/PROPHET.png" alt="image"></td>
          <td></td>
          <td></td>
      </tr>
      <tr>
          <td>算出來結果差不多</td>
          <td></td>
          <td></td>
      </tr>
  </tbody>
</table>
<h4 id="下面實戰">下面實戰</h4>
<pre tabindex="0"><code># -*- coding: utf-8 -*-
&#34;&#34;&#34;使用PROPHET 以及LSTM預測總架次數.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rRZQvGW2IOwRO1i1FZd_wGhz5iagkko6
&#34;&#34;&#34;

# @title
# 設定分割日 mday
mday = pd.to_datetime(&#39;2023-10-1&#39;)

# 建立訓練用 index 與驗證用 index
train_index = df2[&#39;ds&#39;] &lt; mday
test_index = df2[&#39;ds&#39;] &gt;= mday

# 分割輸入資料
x_train = df2[train_index]
x_test = df2[test_index]

# 分割日期資料（用於繪製圖形）
dates_test = df2[&#39;ds&#39;][test_index]

&#34;&#34;&#34;### Read DATA&#34;&#34;&#34;

import pandas as pd

# 直接使用CSV檔案的URL
url = &#39;https://docs.google.com/spreadsheets/d/1hkHrnbn5oQPPHfBhiuieUzmVjsqW20XmRQWkhfWMomE/export?format=csv&amp;id=1hkHrnbn5oQPPHfBhiuieUzmVjsqW20XmRQWkhfWMomE&#39;

# 使用pandas讀取CSV
df = pd.read_csv(url)

# 顯示DataFrame的前幾行
df.head()
df.to_csv(&#39;calendar.csv&#39;, index=False)

import pandas as pd

# 讀取原始 CSV 檔案
df = pd.read_csv(&#39;/content/calender.csv&#39;)

# 確保日期格式正確
df[&#39;ds&#39;] = pd.to_datetime(df[&#39;pla_aircraft_sorties&#39;])

# 可以在這裡進行轉換，例如改欄位名稱、格式等
df.rename(columns={&#39;pla_aircraft_sorties&#39;: &#39;value&#39;}, inplace=True)  # 轉為 Prophet 格式範例
df.rename(columns={&#39;date&#39;: &#39;DATE&#39;}, inplace=True)  # 轉為 Prophet 格式範例

# 儲存為新的 CSV 檔案
df.to_csv(&#39;/content/output.csv&#39;, index=False)

import pandas as pd
from datetime import datetime

def convert_for_prophet(input_file, output_file):
    df = pd.read_csv(input_file)

    df.columns = df.columns.str.strip()


    df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;])


    prophet_df = pd.DataFrame()
    prophet_df[&#39;ds&#39;] = df[&#39;DATE&#39;]
    prophet_df[&#39;value&#39;]=df[&#39;value&#39;]


    prophet_df[&#39;ds&#39;] = prophet_df[&#39;ds&#39;].dt.strftime(&#39;%Y-%m-%d&#39;)


    prophet_df = prophet_df.sort_values(&#39;ds&#39;)


    prophet_df.to_csv(output_file, index=False)
    print(f&#34;\n Save File {output_file}&#34;)

    print(&#34;\n Preview：&#34;)
    print(prophet_df.head())

    return prophet_df

input_file = &#39;output.csv&#39;
output_file = &#39;DEXVZUS_out.csv&#39;
prophet_df = convert_for_prophet(input_file, output_file)

!pip install prophet

# Quandl for financial analysis, pandas and numpy for data manipulation
# fbprophet for additive models, #pytrends for Google trend data
import pandas as pd
import numpy as np
import prophet

# matplotlib pyplot for plotting
import matplotlib.pyplot as plt

import matplotlib

# Class for analyzing and (attempting) to predict future prices
# Contains a number of visualizations and analysis methods
class Stocker():

    # Initialization requires a ticker symbol
    def __init__(self, price):
        self.symbol = &#39;the &#39;
        s = price
        stock = pd.DataFrame({&#39;Date&#39;:s.index, &#39;y&#39;:s, &#39;ds&#39;:s.index, &#39;close&#39;:s,&#39;open&#39;:s}, index=None)

        if (&#39;Adj. Close&#39; not in stock.columns):
            stock[&#39;Adj. Close&#39;] = stock[&#39;close&#39;]
            stock[&#39;Adj. Open&#39;] = stock[&#39;open&#39;]

        stock[&#39;y&#39;] = stock[&#39;Adj. Close&#39;]
        stock[&#39;Daily Change&#39;] = stock[&#39;Adj. Close&#39;] - stock[&#39;Adj. Open&#39;]

        # Data assigned as class attribute
        self.stock = stock.copy()

        # Minimum and maximum date in range
        self.min_date = min(stock[&#39;ds&#39;])
        self.max_date = max(stock[&#39;ds&#39;])

        # Find max and min prices and dates on which they occurred
        self.max_price = np.max(self.stock[&#39;y&#39;])
        self.min_price = np.min(self.stock[&#39;y&#39;])

        self.min_price_date = self.stock[self.stock[&#39;y&#39;] == self.min_price][&#39;ds&#39;]
        self.min_price_date = self.min_price_date[self.min_price_date.index[0]]
        self.max_price_date = self.stock[self.stock[&#39;y&#39;] == self.max_price][&#39;ds&#39;]
        self.max_price_date = self.max_price_date[self.max_price_date.index[0]]

        # The starting price (starting with the opening price)
        self.starting_price = float(self.stock[&#39;Adj. Open&#39;].iloc[0])

        # The most recent price
        self.most_recent_price = float(self.stock[&#39;y&#39;].iloc[len(self.stock) - 1])

        # Whether or not to round dates
        self.round_dates = True

        # Number of years of data to train on
        self.training_years = 3

        # Prophet parameters
        # Default prior from library
        self.changepoint_prior_scale = 0.05
        self.weekly_seasonality = False
        self.daily_seasonality = False
        self.monthly_seasonality = True
        self.yearly_seasonality = True
        self.changepoints = None

        print(&#39;{} Stocker Initialized. Data covers {} to {}.&#39;.format(self.symbol,
                                                                     self.min_date,
                                                                     self.max_date))

    &#34;&#34;&#34;
    Make sure start and end dates are in the range and can be
    converted to pandas datetimes. Returns dates in the correct format
    &#34;&#34;&#34;
    def handle_dates(self, start_date, end_date):


        # Default start and end date are the beginning and end of data
        if start_date is None:
            start_date = self.min_date
        if end_date is None:
            end_date = self.max_date

        try:
            # Convert to pandas datetime for indexing dataframe
            start_date = pd.to_datetime(start_date)
            end_date = pd.to_datetime(end_date)

        except Exception as e:
            print(&#39;Enter valid pandas date format.&#39;)
            print(e)
            return

        valid_start = False
        valid_end = False

        # User will continue to enter dates until valid dates are met
        while (not valid_start) &amp; (not valid_end):
            valid_end = True
            valid_start = True

            if end_date &lt; start_date:
                print(&#39;End Date must be later than start date.&#39;)
                start_date = pd.to_datetime(input(&#39;Enter a new start date: &#39;))
                end_date= pd.to_datetime(input(&#39;Enter a new end date: &#39;))
                valid_end = False
                valid_start = False

            else:
                if end_date &gt; self.max_date:
                    print(&#39;End Date exceeds data range&#39;)
                    end_date= pd.to_datetime(input(&#39;Enter a new end date: &#39;))
                    valid_end = False

                if start_date &lt; self.min_date:
                    print(&#39;Start Date is before date range&#39;)
                    start_date = pd.to_datetime(input(&#39;Enter a new start date: &#39;))
                    valid_start = False


        return start_date, end_date

    &#34;&#34;&#34;
    Return the dataframe trimmed to the specified range.
    &#34;&#34;&#34;
    def make_df(self, start_date, end_date, df=None):

        # Default is to use the object stock data
        if not df:
            df = self.stock.copy()


        start_date, end_date = self.handle_dates(start_date, end_date)

        # keep track of whether the start and end dates are in the data
        start_in = True
        end_in = True

        # If user wants to round dates (default behavior)
        if self.round_dates:
            # Record if start and end date are in df
            if (start_date not in list(df[&#39;Date&#39;])):
                start_in = False
            if (end_date not in list(df[&#39;Date&#39;])):
                end_in = False

            # If both are not in dataframe, round both
            if (not end_in) &amp; (not start_in):
                trim_df = df[(df[&#39;Date&#39;] &gt;= start_date) &amp;
                             (df[&#39;Date&#39;] &lt;= end_date)]

            else:
                # If both are in dataframe, round neither
                if (end_in) &amp; (start_in):
                    trim_df = df[(df[&#39;Date&#39;] &gt;= start_date) &amp;
                                 (df[&#39;Date&#39;] &lt;= end_date)]
                else:
                    # If only start is missing, round start
                    if (not start_in):
                        trim_df = df[(df[&#39;Date&#39;] &gt; start_date) &amp;
                                     (df[&#39;Date&#39;] &lt;= end_date)]
                    # If only end is imssing round end
                    elif (not end_in):
                        trim_df = df[(df[&#39;Date&#39;] &gt;= start_date) &amp;
                                     (df[&#39;Date&#39;] &lt; end_date)]


        else:
            valid_start = False
            valid_end = False
            while (not valid_start) &amp; (not valid_end):
                start_date, end_date = self.handle_dates(start_date, end_date)

                # No round dates, if either data not in, print message and return
                if (start_date in list(df[&#39;Date&#39;])):
                    valid_start = True
                if (end_date in list(df[&#39;Date&#39;])):
                    valid_end = True

                # Check to make sure dates are in the data
                if (start_date not in list(df[&#39;Date&#39;])):
                    print(&#39;Start Date not in data (either out of range or not a trading day.)&#39;)
                    start_date = pd.to_datetime(input(prompt=&#39;Enter a new start date: &#39;))

                elif (end_date not in list(df[&#39;Date&#39;])):
                    print(&#39;End Date not in data (either out of range or not a trading day.)&#39;)
                    end_date = pd.to_datetime(input(prompt=&#39;Enter a new end date: &#39;) )

            # Dates are not rounded
            trim_df = df[(df[&#39;Date&#39;] &gt;= start_date) &amp;
                         (df[&#39;Date&#39;] &lt;= end_date)]



        return trim_df


    # Basic Historical Plots and Basic Statistics
    def plot_stock(self, start_date=None, end_date=None, stats=[&#39;Adj. Close&#39;], plot_type=&#39;basic&#39;):

        self.reset_plot()

        if start_date is None:
            start_date = self.min_date
        if end_date is None:
            end_date = self.max_date

        stock_plot = self.make_df(start_date, end_date)

        colors = [&#39;r&#39;, &#39;b&#39;, &#39;g&#39;, &#39;y&#39;, &#39;c&#39;, &#39;m&#39;]

        for i, stat in enumerate(stats):

            stat_min = min(stock_plot[stat])
            stat_max = max(stock_plot[stat])

            stat_avg = np.mean(stock_plot[stat])

            date_stat_min = stock_plot[stock_plot[stat] == stat_min][&#39;Date&#39;]
            date_stat_min = date_stat_min[date_stat_min.index[0]]
            date_stat_max = stock_plot[stock_plot[stat] == stat_max][&#39;Date&#39;]
            date_stat_max = date_stat_max[date_stat_max.index[0]]

            print(&#39;Maximum {} = {:.2f} on {}.&#39;.format(stat, stat_max, date_stat_max))
            print(&#39;Minimum {} = {:.2f} on {}.&#39;.format(stat, stat_min, date_stat_min))
            print(&#39;Current {} = {:.2f} on {}.\n&#39;.format(stat, self.stock[stat].iloc[len(self.stock) - 1], self.max_date.date()))

            # Percentage y-axis
            if plot_type == &#39;pct&#39;:
                # Simple Plot
                plt.style.use(&#39;fivethirtyeight&#39;);
                if stat == &#39;Daily Change&#39;:
                    plt.plot(stock_plot[&#39;Date&#39;], 100 * stock_plot[stat],
                         color = colors[i], linewidth = 2.4, alpha = 0.9,
                         label = stat)
                else:
                    plt.plot(stock_plot[&#39;Date&#39;], 100 * (stock_plot[stat] -  stat_avg) / stat_avg,
                         color = colors[i], linewidth = 2.4, alpha = 0.9,
                         label = stat)

                plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;Change Relative to Average (%)&#39;); plt.title(&#39;%s Currency History&#39; % self.symbol);
                plt.legend(prop={&#39;size&#39;:10})
                plt.grid(color = &#39;k&#39;, alpha = 0.4);

            # Stat y-axis
            elif plot_type == &#39;basic&#39;:
                plt.style.use(&#39;fivethirtyeight&#39;);
                plt.plot(stock_plot[&#39;Date&#39;], stock_plot[stat], color = colors[i], linewidth = 3, label = stat, alpha = 0.8)
                plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;US $&#39;); plt.title(&#39;%s Currency History&#39; % self.symbol);
                plt.legend(prop={&#39;size&#39;:10})
                plt.grid(color = &#39;k&#39;, alpha = 0.4);

        plt.show();

    # Reset the plotting parameters to clear style formatting
    # Not sure if this should be a static method
    @staticmethod
    def reset_plot():

        # Restore default parameters
        matplotlib.rcParams.update(matplotlib.rcParamsDefault)

        # Adjust a few parameters to liking
        matplotlib.rcParams[&#39;figure.figsize&#39;] = (8, 5)
        matplotlib.rcParams[&#39;axes.labelsize&#39;] = 10
        matplotlib.rcParams[&#39;xtick.labelsize&#39;] = 8
        matplotlib.rcParams[&#39;ytick.labelsize&#39;] = 8
        matplotlib.rcParams[&#39;axes.titlesize&#39;] = 14
        matplotlib.rcParams[&#39;text.color&#39;] = &#39;k&#39;

    # Method to linearly interpolate prices on the weekends
    def resample(self, dataframe):
        # Change the index and resample at daily level
        dataframe = dataframe.set_index(&#39;ds&#39;)
        dataframe = dataframe.resample(&#39;D&#39;)

        # Reset the index and interpolate nan values
        dataframe = dataframe.reset_index(level=0)
        dataframe = dataframe.interpolate()
        return dataframe

    # Remove weekends from a dataframe
    def remove_weekends(self, dataframe):

        # Reset index to use ix
        dataframe = dataframe.reset_index(drop=True)

        weekends = []

        # Find all of the weekends
        for i, date in enumerate(dataframe[&#39;ds&#39;]):
            if (date.weekday()) == 5 | (date.weekday() == 6):
                weekends.append(i)

        # Drop the weekends
        dataframe = dataframe.drop(weekends, axis=0)

        return dataframe


    # Calculate and plot profit from buying and holding shares for specified date range
    def buy_and_hold(self, start_date=None, end_date=None, nshares=1):
        self.reset_plot()

        start_date, end_date = self.handle_dates(start_date, end_date)

        # Find starting and ending price of stock
        start_price = float(self.stock[self.stock[&#39;Date&#39;] == start_date][&#39;Adj. Open&#39;])
        end_price = float(self.stock[self.stock[&#39;Date&#39;] == end_date][&#39;Adj. Close&#39;])

        # Make a profit dataframe and calculate profit column
        profits = self.make_df(start_date, end_date)
        profits[&#39;hold_profit&#39;] = nshares * (profits[&#39;Adj. Close&#39;] - start_price)

        # Total profit
        total_hold_profit = nshares * (end_price - start_price)

        print(&#39;{} Total buy and hold profit from {} to {} for {} shares = ${:.2f}&#39;.format
              (self.symbol, start_date, end_date, nshares, total_hold_profit))

        # Plot the total profits
        plt.style.use(&#39;dark_background&#39;)

        # Location for number of profit
        text_location = (end_date - pd.DateOffset(months = 1))

        # Plot the profits over time
        plt.plot(profits[&#39;Date&#39;], profits[&#39;hold_profit&#39;], &#39;b&#39;, linewidth = 3)
        plt.ylabel(&#39;Profit ($)&#39;); plt.xlabel(&#39;Date&#39;); plt.title(&#39;Buy and Hold Profits for {} {} to {}&#39;.format(
                                                                self.symbol, start_date, end_date))

        # Display final value on graph
        plt.text(x = text_location,
             y =  total_hold_profit + (total_hold_profit / 40),
             s = &#39;$%d&#39; % total_hold_profit,
            color = &#39;g&#39; if total_hold_profit &gt; 0 else &#39;r&#39;,
            size = 14)

        plt.grid(alpha=0.2)
        plt.show();

    # Create a prophet model without training
    def create_model(self):

        # Make the model
        model = prophet.Prophet(daily_seasonality=self.daily_seasonality,
                                  weekly_seasonality=self.weekly_seasonality,
                                  yearly_seasonality=self.yearly_seasonality,
                                  changepoint_prior_scale=self.changepoint_prior_scale,
                                  changepoints=self.changepoints)

        if self.monthly_seasonality:
            # Add monthly seasonality
            model.add_seasonality(name = &#39;monthly&#39;, period = 30.5, fourier_order = 5)

        return model

    # Graph the effects of altering the changepoint prior scale (cps)
    def changepoint_prior_analysis(self, changepoint_priors=[0.001, 0.05, 0.1, 0.2], colors=[&#39;b&#39;, &#39;r&#39;, &#39;grey&#39;, &#39;gold&#39;]):

        # Training and plotting with specified years of data
        train = self.stock[(self.stock[&#39;Date&#39;] &gt; (max(self.stock[&#39;Date&#39;]
                                                     ) - pd.DateOffset(years=self.training_years)))]

        # Iterate through all the changepoints and make models
        for i, prior in enumerate(changepoint_priors):
            # Select the changepoint
            self.changepoint_prior_scale = prior

            # Create and train a model with the specified cps
            model = self.create_model()
            model.fit(train)
            future = model.make_future_dataframe(periods=180, freq=&#39;D&#39;)

            # Make a dataframe to hold predictions
            if i == 0:
                predictions = future.copy()

            future = model.predict(future)

            # Fill in prediction dataframe
            predictions[&#39;%.3f_yhat_upper&#39; % prior] = future[&#39;yhat_upper&#39;]
            predictions[&#39;%.3f_yhat_lower&#39; % prior] = future[&#39;yhat_lower&#39;]
            predictions[&#39;%.3f_yhat&#39; % prior] = future[&#39;yhat&#39;]

        # Remove the weekends
        predictions = self.remove_weekends(predictions)

        # Plot set-up
        self.reset_plot()
        plt.style.use(&#39;fivethirtyeight&#39;)
        fig, ax = plt.subplots(1, 1)

        # Actual observations
        ax.plot(train[&#39;ds&#39;], train[&#39;y&#39;], &#39;ko&#39;, ms = 4, label = &#39;Observations&#39;)
        color_dict = {prior: color for prior, color in zip(changepoint_priors, colors)}

        # Plot each of the changepoint predictions
        for prior in changepoint_priors:
            # Plot the predictions themselves
            ax.plot(predictions[&#39;ds&#39;], predictions[&#39;%.3f_yhat&#39; % prior], linewidth = 1.2,
                     color = color_dict[prior], label = &#39;%.3f prior scale&#39; % prior)

            # Plot the uncertainty interval
            ax.fill_between(predictions[&#39;ds&#39;].dt.to_pydatetime(), predictions[&#39;%.3f_yhat_upper&#39; % prior],
                            predictions[&#39;%.3f_yhat_lower&#39; % prior], facecolor = color_dict[prior],
                            alpha = 0.3, edgecolor = &#39;k&#39;, linewidth = 0.6)

        # Plot labels
        plt.legend(loc = 2, prop={&#39;size&#39;: 10})
        plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;Stock Price ($)&#39;); plt.title(&#39;Effect of Changepoint Prior Scale&#39;);
        plt.show()

    # Basic prophet model for specified number of days
    def create_prophet_model(self, days=0, resample=False):

        self.reset_plot()

        model = self.create_model()

        # Fit on the stock history for self.training_years number of years
        stock_history = self.stock[self.stock[&#39;Date&#39;] &gt; (self.max_date -
                                                         pd.DateOffset(years = self.training_years))]

        if resample:
            stock_history = self.resample(stock_history)

        model.fit(stock_history)

        # Make and predict for next year with future dataframe
        future = model.make_future_dataframe(periods = days, freq=&#39;D&#39;)
        future = model.predict(future)

        if days &gt; 0:
            # Print the predicted price
            predicted_date = future[&#39;ds&#39;].iloc[-1]
            predicted_value = future[&#39;yhat&#39;].iloc[-1]
            print(&#39;Predicted Index on {} = ${:.2f}&#39;.format(predicted_date, predicted_value))

            title = &#39;%s Historical and Predicted bolivars Index&#39;  % self.symbol
        else:
            title = &#39;%s Historical and Modeled bolivars Index&#39; % self.symbol

        # Set up the plot
        fig, ax = plt.subplots(1, 1)

        # Plot the actual values
        ax.plot(stock_history[&#39;ds&#39;], stock_history[&#39;y&#39;], &#39;ko-&#39;, linewidth = 1.4, alpha = 0.8, ms = 1.8, label = &#39;Observations&#39;)

        # Plot the predicted values
        ax.plot(future[&#39;ds&#39;], future[&#39;yhat&#39;], &#39;forestgreen&#39;,linewidth = 2.4, label = &#39;Modeled&#39;);

        # Plot the uncertainty interval as ribbon
        ax.fill_between(np.array(future[&#39;ds&#39;].dt.to_pydatetime()),
                future[&#39;yhat_upper&#39;],
                future[&#39;yhat_lower&#39;],
                alpha=0.3, facecolor=&#39;g&#39;, edgecolor=&#39;k&#39;, linewidth=1.4)

        # Plot formatting
        plt.legend(loc = 2, prop={&#39;size&#39;: 10}); plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;Index $&#39;);
        plt.grid(linewidth=0.6, alpha = 0.6)
        plt.title(title);
        plt.show()

        return model, future

    # Evaluate prediction model for one year
    def evaluate_prediction(self, start_date=None, end_date=None, nshares = None):

        # Default start date is one year before end of data
        # Default end date is end date of data
        if start_date is None:
            start_date = self.max_date - pd.DateOffset(years=1)
        if end_date is None:
            end_date = self.max_date

        start_date, end_date = self.handle_dates(start_date, end_date)

        # Training data starts self.training_years years before start date and goes up to start date
        train = self.stock[(self.stock[&#39;Date&#39;] &lt; start_date) &amp;
                           (self.stock[&#39;Date&#39;] &gt; (start_date - pd.DateOffset(years=self.training_years)))]

        # Testing data is specified in the range
        test = self.stock[(self.stock[&#39;Date&#39;] &gt;= start_date) &amp; (self.stock[&#39;Date&#39;] &lt;= end_date)]

        # Create and train the model
        model = self.create_model()
        model.fit(train)

        # Make a future dataframe and predictions
        future = model.make_future_dataframe(periods = 365, freq=&#39;D&#39;)
        future = model.predict(future)

        # Merge predictions with the known values
        test = pd.merge(test, future, on = &#39;ds&#39;, how = &#39;inner&#39;)

        train = pd.merge(train, future, on = &#39;ds&#39;, how = &#39;inner&#39;)

        # Calculate the differences between consecutive measurements
        test[&#39;pred_diff&#39;] = test[&#39;yhat&#39;].diff()
        test[&#39;real_diff&#39;] = test[&#39;y&#39;].diff()

        # Correct is when we predicted the correct direction
        test[&#39;correct&#39;] = (np.sign(test[&#39;pred_diff&#39;]) == np.sign(test[&#39;real_diff&#39;])) * 1

        # Accuracy when we predict increase and decrease
        increase_accuracy = 100 * np.mean(test[test[&#39;pred_diff&#39;] &gt; 0][&#39;correct&#39;])
        decrease_accuracy = 100 * np.mean(test[test[&#39;pred_diff&#39;] &lt; 0][&#39;correct&#39;])

        # Calculate mean absolute error
        test_errors = abs(test[&#39;y&#39;] - test[&#39;yhat&#39;])
        test_mean_error = np.mean(test_errors)

        train_errors = abs(train[&#39;y&#39;] - train[&#39;yhat&#39;])
        train_mean_error = np.mean(train_errors)

        # Calculate percentage of time actual value within prediction range
        test[&#39;in_range&#39;] = False

        for i in test.index:
            if (test[&#39;y&#39;].iloc[i] &lt; test[&#39;yhat_upper&#39;].iloc[i]) &amp; (test[&#39;y&#39;].iloc[i] &gt; test[&#39;yhat_lower&#39;].iloc[i]):
                test[&#39;in_range&#39;].iloc[i] = True

        in_range_accuracy = 100 * np.mean(test[&#39;in_range&#39;])

        if not nshares:

            # Date range of predictions
            print(&#39;\nPrediction Range: {} to {}.&#39;.format(start_date,
                end_date))

            # Final prediction vs actual value
            print(&#39;\nPredicted price on {} = ${:.2f}.&#39;.format(max(future[&#39;ds&#39;]), future[&#39;yhat&#39;].iloc[len(future) - 1]))
            print(&#39;Actual price on    {} = ${:.2f}.\n&#39;.format(max(test[&#39;ds&#39;]), test[&#39;y&#39;].iloc[len(test) - 1]))

            print(&#39;Average Absolute Error on Training Data = ${:.2f}.&#39;.format(train_mean_error))
            print(&#39;Average Absolute Error on Testing  Data = ${:.2f}.\n&#39;.format(test_mean_error))

            # Direction accuracy
            print(&#39;When the model predicted an increase, the price increased {:.2f}% of the time.&#39;.format(increase_accuracy))
            print(&#39;When the model predicted a  decrease, the price decreased  {:.2f}% of the time.\n&#39;.format(decrease_accuracy))

            print(&#39;The actual value was within the {:d}% confidence interval {:.2f}% of the time.&#39;.format(int(100 * model.interval_width), in_range_accuracy))


             # Reset the plot
            self.reset_plot()

            # Set up the plot
            fig, ax = plt.subplots(1, 1)

            # Plot the actual values
            ax.plot(train[&#39;ds&#39;], train[&#39;y&#39;], &#39;ko-&#39;, linewidth = 1.4, alpha = 0.8, ms = 1.8, label = &#39;Observations&#39;)
            ax.plot(test[&#39;ds&#39;], test[&#39;y&#39;], &#39;ko-&#39;, linewidth = 1.4, alpha = 0.8, ms = 1.8, label = &#39;Observations&#39;)

            # Plot the predicted values
            ax.plot(future[&#39;ds&#39;], future[&#39;yhat&#39;], &#39;navy&#39;, linewidth = 2.4, label = &#39;Predicted&#39;);

            # Plot the uncertainty interval as ribbon
            ax.fill_between(future[&#39;ds&#39;].dt.to_pydatetime(), future[&#39;yhat_upper&#39;], future[&#39;yhat_lower&#39;], alpha = 0.6,
                           facecolor = &#39;gold&#39;, edgecolor = &#39;k&#39;, linewidth = 1.4, label = &#39;Confidence Interval&#39;)

            # Put a vertical line at the start of predictions
            plt.vlines(x=min(test[&#39;ds&#39;]), ymin=min(future[&#39;yhat_lower&#39;]), ymax=max(future[&#39;yhat_upper&#39;]), colors = &#39;r&#39;,
                       linestyles=&#39;dashed&#39;, label = &#39;Prediction Start&#39;)

            # Plot formatting
            plt.legend(loc = 2, prop={&#39;size&#39;: 8}); plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;Price $&#39;);
            plt.grid(linewidth=0.6, alpha = 0.6)

            plt.title(&#39;{} Model Evaluation from {} to {}.&#39;.format(self.symbol,
                start_date, end_date));
            plt.show();


        # If a number of shares is specified, play the game
        elif nshares:

            # Only playing the stocks when we predict the stock will increase
            test_pred_increase = test[test[&#39;pred_diff&#39;] &gt; 0]

            test_pred_increase.reset_index(inplace=True)
            prediction_profit = []

            # Iterate through all the predictions and calculate profit from playing
            for i, correct in enumerate(test_pred_increase[&#39;correct&#39;]):

                # If we predicted up and the price goes up, we gain the difference
                if correct == 1:
                    prediction_profit.append(nshares * test_pred_increase[&#39;real_diff&#39;].iloc[i])
                # If we predicted up and the price goes down, we lose the difference
                else:
                    prediction_profit.append(nshares * test_pred_increase[&#39;real_diff&#39;].iloc[i])

            test_pred_increase[&#39;pred_profit&#39;] = prediction_profit

            # Put the profit into the test dataframe
            test = pd.merge(test, test_pred_increase[[&#39;ds&#39;, &#39;pred_profit&#39;]], on = &#39;ds&#39;, how = &#39;left&#39;)
            test[&#39;pred_profit&#39;].iloc[0] = 0

            # Profit for either method at all dates
            test[&#39;pred_profit&#39;] = test[&#39;pred_profit&#39;].cumsum().ffill()
            test[&#39;hold_profit&#39;] = nshares * (test[&#39;y&#39;] - float(test[&#39;y&#39;].iloc[0]))

            # Display information
            print(&#39;You played the stock market in {} from {} to {} with {} shares.\n&#39;.format(
                self.symbol, start_date, end_date, nshares))

            print(&#39;When the model predicted an increase, the price increased {:.2f}% of the time.&#39;.format(increase_accuracy))
            print(&#39;When the model predicted a  decrease, the price decreased  {:.2f}% of the time.\n&#39;.format(decrease_accuracy))

            # Display some friendly information about the perils of playing the stock market
            print(&#39;The total profit using the Prophet model = ${:.2f}.&#39;.format(np.sum(prediction_profit)))
            print(&#39;The Buy and Hold strategy profit =         ${:.2f}.&#39;.format(float(test[&#39;hold_profit&#39;].iloc[len(test) - 1])))
            print(&#39;\nThanks for playing the stock market!\n&#39;)



            # Plot the predicted and actual profits over time
            self.reset_plot()

            # Final profit and final smart used for locating text
            final_profit = test[&#39;pred_profit&#39;].iloc[len(test) - 1]
            final_smart = test[&#39;hold_profit&#39;].iloc[len(test) - 1]

            # text location
            last_date = test[&#39;ds&#39;].iloc[len(test) - 1]
            text_location = (last_date - pd.DateOffset(months = 1))

            plt.style.use(&#39;dark_background&#39;)

            # Plot smart profits
            plt.plot(test[&#39;ds&#39;], test[&#39;hold_profit&#39;], &#39;b&#39;,
                     linewidth = 1.8, label = &#39;Buy and Hold Strategy&#39;)

            # Plot prediction profits
            plt.plot(test[&#39;ds&#39;], test[&#39;pred_profit&#39;],
                     color = &#39;g&#39; if final_profit &gt; 0 else &#39;r&#39;,
                     linewidth = 1.8, label = &#39;Prediction Strategy&#39;)

            # Display final values on graph
            plt.text(x = text_location,
                     y =  final_profit + (final_profit / 40),
                     s = &#39;$%d&#39; % final_profit,
                    color = &#39;g&#39; if final_profit &gt; 0 else &#39;r&#39;,
                    size = 18)

            plt.text(x = text_location,
                     y =  final_smart + (final_smart / 40),
                     s = &#39;$%d&#39; % final_smart,
                    color = &#39;g&#39; if final_smart &gt; 0 else &#39;r&#39;,
                    size = 18);

            # Plot formatting
            plt.ylabel(&#39;Profit  (US $)&#39;); plt.xlabel(&#39;Date&#39;);
            plt.title(&#39;Predicted versus Buy and Hold Profits&#39;);
            plt.legend(loc = 2, prop={&#39;size&#39;: 10});
            plt.grid(alpha=0.2);
            plt.show()

    def retrieve_google_trends(self, search, date_range):

        # Set up the trend fetching object
        pytrends = TrendReq(hl=&#39;en-US&#39;, tz=360)
        kw_list = [search]

        try:

            # Create the search object
            pytrends.build_payload(kw_list, cat=0, timeframe=date_range[0], geo=&#39;&#39;, gprop=&#39;news&#39;)

            # Retrieve the interest over time
            trends = pytrends.interest_over_time()

            related_queries = pytrends.related_queries()

        except Exception as e:
            print(&#39;\nGoogle Search Trend retrieval failed.&#39;)
            print(e)
            return

        return trends, related_queries

    def changepoint_date_analysis(self, search=None):
        self.reset_plot()

        model = self.create_model()

        # Use past self.training_years years of data
        train = self.stock[self.stock[&#39;Date&#39;] &gt; (self.max_date - pd.DateOffset(years = self.training_years))]
        model.fit(train)

        # Predictions of the training data (no future periods)
        future = model.make_future_dataframe(periods=0, freq=&#39;D&#39;)
        future = model.predict(future)

        train = pd.merge(train, future[[&#39;ds&#39;, &#39;yhat&#39;]], on = &#39;ds&#39;, how = &#39;inner&#39;)

        changepoints = model.changepoints
        train = train.reset_index(drop=True)

        # Create dataframe of only changepoints
        change_indices = []
        for changepoint in (changepoints):
            change_indices.append(train[train[&#39;ds&#39;] == changepoint].index[0])

        c_data = train.iloc[change_indices, :]
        deltas = model.params[&#39;delta&#39;][0]

        c_data[&#39;delta&#39;] = deltas
        c_data[&#39;abs_delta&#39;] = abs(c_data[&#39;delta&#39;])

        # Sort the values by maximum change
        c_data = c_data.sort_values(by=&#39;abs_delta&#39;, ascending=False)

        # Limit to 10 largest changepoints
        c_data = c_data[:10]

        # Separate into negative and positive changepoints
        cpos_data = c_data[c_data[&#39;delta&#39;] &gt; 0]
        cneg_data = c_data[c_data[&#39;delta&#39;] &lt; 0]

        # Changepoints and data
        if not search:

            print(&#39;\nChangepoints sorted by slope rate of change (2nd derivative):\n&#39;)
            print(c_data[[&#39;Date&#39;, &#39;Adj. Close&#39;, &#39;delta&#39;]][:5])

            # Line plot showing actual values, estimated values, and changepoints
            self.reset_plot()

            # Set up line plot
            plt.plot(train[&#39;ds&#39;], train[&#39;y&#39;], &#39;ko&#39;, ms = 4, label = &#39;Stock Price&#39;)
            plt.plot(future[&#39;ds&#39;], future[&#39;yhat&#39;], color = &#39;navy&#39;, linewidth = 2.0, label = &#39;Modeled&#39;)

            # Changepoints as vertical lines
            plt.vlines(cpos_data[&#39;ds&#39;].dt.to_pydatetime(), ymin = min(train[&#39;y&#39;]), ymax = max(train[&#39;y&#39;]),
                       linestyles=&#39;dashed&#39;, color = &#39;r&#39;,
                       linewidth= 1.2, label=&#39;Negative Changepoints&#39;)

            plt.vlines(cneg_data[&#39;ds&#39;].dt.to_pydatetime(), ymin = min(train[&#39;y&#39;]), ymax = max(train[&#39;y&#39;]),
                       linestyles=&#39;dashed&#39;, color = &#39;darkgreen&#39;,
                       linewidth= 1.2, label=&#39;Positive Changepoints&#39;)

            plt.legend(prop={&#39;size&#39;:10});
            plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;Price ($)&#39;); plt.title(&#39;Stock Price with Changepoints&#39;)
            plt.show()

        # Search for search term in google news
        # Show related queries, rising related queries
        # Graph changepoints, search frequency, stock price
        if search:
            date_range = [&#39;%s %s&#39; % (str(min(train[&#39;Date&#39;])), str(max(train[&#39;Date&#39;])))]

            # Get the Google Trends for specified terms and join to training dataframe
            trends, related_queries = self.retrieve_google_trends(search, date_range)

            if (trends is None)  or (related_queries is None):
                print(&#39;No search trends found for %s&#39; % search)
                return

            print(&#39;\n Top Related Queries: \n&#39;)
            print(related_queries[search][&#39;top&#39;].head())

            print(&#39;\n Rising Related Queries: \n&#39;)
            print(related_queries[search][&#39;rising&#39;].head())

            # Upsample the data for joining with training data
            trends = trends.resample(&#39;D&#39;)

            trends = trends.reset_index(level=0)
            trends = trends.rename(columns={&#39;date&#39;: &#39;ds&#39;, search: &#39;freq&#39;})

            # Interpolate the frequency
            trends[&#39;freq&#39;] = trends[&#39;freq&#39;].interpolate()

            # Merge with the training data
            train = pd.merge(train, trends, on = &#39;ds&#39;, how = &#39;inner&#39;)

            # Normalize values
            train[&#39;y_norm&#39;] = train[&#39;y&#39;] / max(train[&#39;y&#39;])
            train[&#39;freq_norm&#39;] = train[&#39;freq&#39;] / max(train[&#39;freq&#39;])

            self.reset_plot()

            # Plot the normalized stock price and normalize search frequency
            plt.plot(train[&#39;ds&#39;], train[&#39;y_norm&#39;], &#39;k-&#39;, label = &#39;Stock Price&#39;)
            plt.plot(train[&#39;ds&#39;], train[&#39;freq_norm&#39;], color=&#39;goldenrod&#39;, label = &#39;Search Frequency&#39;)

            # Changepoints as vertical lines
            plt.vlines(cpos_data[&#39;ds&#39;].dt.to_pydatetime(), ymin = 0, ymax = 1,
                       linestyles=&#39;dashed&#39;, color = &#39;r&#39;,
                       linewidth= 1.2, label=&#39;Negative Changepoints&#39;)

            plt.vlines(cneg_data[&#39;ds&#39;].dt.to_pydatetime(), ymin = 0, ymax = 1,
                       linestyles=&#39;dashed&#39;, color = &#39;darkgreen&#39;,
                       linewidth= 1.2, label=&#39;Positive Changepoints&#39;)

            # Plot formatting
            plt.legend(prop={&#39;size&#39;: 10})
            plt.xlabel(&#39;Date&#39;); plt.ylabel(&#39;Normalized Values&#39;); plt.title(&#39;%s Stock Price and Search Frequency for %s&#39; % (self.symbol, search))
            plt.show()

    # Predict the future price for a given range of days
    def predict_future(self, days=30):

        # Use past self.training_years years for training
        train = self.stock[self.stock[&#39;Date&#39;] &gt; (max(self.stock[&#39;Date&#39;]
                                                    ) - pd.DateOffset(years=self.training_years))]

        model = self.create_model()

        model.fit(train)

        # Future dataframe with specified number of days to predict
        future = model.make_future_dataframe(periods=days, freq=&#39;D&#39;)
        future = model.predict(future)

        # Only concerned with future dates
        future = future[future[&#39;ds&#39;] &gt;= max(self.stock[&#39;Date&#39;])]

        # Remove the weekends
        future = self.remove_weekends(future)

        # Calculate whether increase or not
        future[&#39;diff&#39;] = future[&#39;yhat&#39;].diff()

        future = future.dropna()

        # Find the prediction direction and create separate dataframes
        future[&#39;direction&#39;] = (future[&#39;diff&#39;] &gt; 0) * 1

        # Rename the columns for presentation
        future = future.rename(columns={&#39;ds&#39;: &#39;Date&#39;, &#39;yhat&#39;: &#39;estimate&#39;, &#39;diff&#39;: &#39;change&#39;,
                                        &#39;yhat_upper&#39;: &#39;upper&#39;, &#39;yhat_lower&#39;: &#39;lower&#39;})

        future_increase = future[future[&#39;direction&#39;] == 1]
        future_decrease = future[future[&#39;direction&#39;] == 0]

        # Print out the dates
        print(&#39;\nPredicted Increase: \n&#39;)
        print(future_increase[[&#39;Date&#39;, &#39;estimate&#39;, &#39;change&#39;, &#39;upper&#39;, &#39;lower&#39;]])

        print(&#39;\nPredicted Decrease: \n&#39;)
        print(future_decrease[[&#39;Date&#39;, &#39;estimate&#39;, &#39;change&#39;, &#39;upper&#39;, &#39;lower&#39;]])

        self.reset_plot()

        # Set up plot
        plt.style.use(&#39;fivethirtyeight&#39;)
        matplotlib.rcParams[&#39;axes.labelsize&#39;] = 10
        matplotlib.rcParams[&#39;xtick.labelsize&#39;] = 8
        matplotlib.rcParams[&#39;ytick.labelsize&#39;] = 8
        matplotlib.rcParams[&#39;axes.titlesize&#39;] = 12

        # Plot the predictions and indicate if increase or decrease
        fig, ax = plt.subplots(1, 1, figsize=(8, 6))

        # Plot the estimates
        ax.plot(future_increase[&#39;Date&#39;], future_increase[&#39;estimate&#39;], &#39;g^&#39;, ms = 12, label = &#39;Pred. Increase&#39;)
        ax.plot(future_decrease[&#39;Date&#39;], future_decrease[&#39;estimate&#39;], &#39;rv&#39;, ms = 12, label = &#39;Pred. Decrease&#39;)

        # Plot errorbars
        ax.errorbar(future[&#39;Date&#39;].dt.to_pydatetime(), future[&#39;estimate&#39;],
                    yerr = future[&#39;upper&#39;] - future[&#39;lower&#39;],
                    capthick=1.4, color = &#39;k&#39;,linewidth = 2,
                   ecolor=&#39;darkblue&#39;, capsize = 4, elinewidth = 1, label = &#39;Pred with Range&#39;)

        # Plot formatting
        plt.legend(loc = 2, prop={&#39;size&#39;: 10});
        plt.xticks(rotation = &#39;45&#39;)
        plt.ylabel(&#39;Predicted  Price (US $)&#39;);
        plt.xlabel(&#39;Date&#39;); plt.title(&#39;Predictions for %s&#39; % self.symbol);
        plt.show()

    def changepoint_prior_validation(self, start_date=None, end_date=None,changepoint_priors = [0.001, 0.05, 0.1, 0.2]):


        # Default start date is two years before end of data
        # Default end date is one year before end of data
        if start_date is None:
            start_date = self.max_date - pd.DateOffset(years=2)
        if end_date is None:
            end_date = self.max_date - pd.DateOffset(years=1)

        # Convert to pandas datetime for indexing dataframe
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)

        start_date, end_date = self.handle_dates(start_date, end_date)

        # Select self.training_years number of years
        train = self.stock[(self.stock[&#39;Date&#39;] &gt; (start_date - pd.DateOffset(years=self.training_years))) &amp;
        (self.stock[&#39;Date&#39;] &lt; start_date)]

        # Testing data is specified by range
        test = self.stock[(self.stock[&#39;Date&#39;] &gt;= start_date) &amp; (self.stock[&#39;Date&#39;] &lt;= end_date)]

        eval_days = (max(test[&#39;Date&#39;]) - min(test[&#39;Date&#39;])).days

        results = pd.DataFrame(0, index = list(range(len(changepoint_priors))),
            columns = [&#39;cps&#39;, &#39;train_err&#39;, &#39;train_range&#39;, &#39;test_err&#39;, &#39;test_range&#39;])

        print(&#39;\nValidation Range {} to {}.\n&#39;.format(min(test[&#39;Date&#39;]),
            max(test[&#39;Date&#39;])))


        # Iterate through all the changepoints and make models
        for i, prior in enumerate(changepoint_priors):
            results[&#39;cps&#39;].iloc[i] = prior

            # Select the changepoint
            self.changepoint_prior_scale = prior

            # Create and train a model with the specified cps
            model = self.create_model()
            model.fit(train)
            future = model.make_future_dataframe(periods=eval_days, freq=&#39;D&#39;)

            future = model.predict(future)

            # Training results and metrics
            train_results = pd.merge(train, future[[&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_upper&#39;, &#39;yhat_lower&#39;]], on = &#39;ds&#39;, how = &#39;inner&#39;)
            avg_train_error = np.mean(abs(train_results[&#39;y&#39;] - train_results[&#39;yhat&#39;]))
            avg_train_uncertainty = np.mean(abs(train_results[&#39;yhat_upper&#39;] - train_results[&#39;yhat_lower&#39;]))

            results[&#39;train_err&#39;].iloc[i] = avg_train_error
            results[&#39;train_range&#39;].iloc[i] = avg_train_uncertainty

            # Testing results and metrics
            test_results = pd.merge(test, future[[&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_upper&#39;, &#39;yhat_lower&#39;]], on = &#39;ds&#39;, how = &#39;inner&#39;)
            avg_test_error = np.mean(abs(test_results[&#39;y&#39;] - test_results[&#39;yhat&#39;]))
            avg_test_uncertainty = np.mean(abs(test_results[&#39;yhat_upper&#39;] - test_results[&#39;yhat_lower&#39;]))

            results[&#39;test_err&#39;].iloc[i] = avg_test_error
            results[&#39;test_range&#39;].iloc[i] = avg_test_uncertainty

        print(results)



        # Plot of training and testing average errors
        self.reset_plot()

        plt.plot(results[&#39;cps&#39;], results[&#39;train_err&#39;], &#39;bo-&#39;, ms = 8, label = &#39;Train Error&#39;)
        plt.plot(results[&#39;cps&#39;], results[&#39;test_err&#39;], &#39;r*-&#39;, ms = 8, label = &#39;Test Error&#39;)
        plt.xlabel(&#39;Changepoint Prior Scale&#39;); plt.ylabel(&#39;Avg. Absolute Error ($)&#39;);
        plt.title(&#39;Training and Testing Curves as Function of CPS&#39;)
        plt.grid(color=&#39;k&#39;, alpha=0.3)
        plt.xticks(results[&#39;cps&#39;], results[&#39;cps&#39;])
        plt.legend(prop={&#39;size&#39;:10})
        plt.show();

        # Plot of training and testing average uncertainty
        self.reset_plot()

        plt.plot(results[&#39;cps&#39;], results[&#39;train_range&#39;], &#39;bo-&#39;, ms = 8, label = &#39;Train Range&#39;)
        plt.plot(results[&#39;cps&#39;], results[&#39;test_range&#39;], &#39;r*-&#39;, ms = 8, label = &#39;Test Range&#39;)
        plt.xlabel(&#39;Changepoint Prior Scale&#39;); plt.ylabel(&#39;Avg. Uncertainty ($)&#39;);
        plt.title(&#39;Uncertainty in Estimate as Function of CPS&#39;)
        plt.grid(color=&#39;k&#39;, alpha=0.3)
        plt.xticks(results[&#39;cps&#39;], results[&#39;cps&#39;])
        plt.legend(prop={&#39;size&#39;:10})
        plt.show();

import pandas as pd

# 讀入資料
df = pd.read_csv(&#39;/content/DEXVZUS_out.csv&#39;, index_col=&#39;ds&#39;, parse_dates=[&#39;ds&#39;])

# 先用中位數補齊 NaN（每欄各自補自己的中位數）
df_filled = df.fillna(df.median(numeric_only=True))

# 再執行 squeeze（若只有一欄，才會變成 Series）
price = df_filled.squeeze()

# 檢查結果
print(price.tail())

DEXVZUS= Stocker(price)

model, model_data = DEXVZUS.create_prophet_model(days=1 )



import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# Prepare data
df = pd.read_csv(&#39;output.csv&#39;)  # Replace with your actual data loading method
df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;])
df = df.rename(columns={&#39;DATE&#39;: &#39;date&#39;, &#39;value&#39;: &#39;value&#39;})

# Create lag features (滯後特徵)
def create_lag_features(data, lag=1):
    lagged_data = data.copy()
    for i in range(1, lag+1):
        lagged_data[f&#39;lag_{i}&#39;] = lagged_data[&#39;value&#39;].shift(i)
    return lagged_data.dropna()

# Create lag features (加入前幾天的價格)
lag = 3  # Use last 3 days to predict
df_lagged = create_lag_features(df, lag)

# Scale the data
scaler = MinMaxScaler()
values_scaled = scaler.fit_transform(df_lagged[&#39;value&#39;].values.reshape(-1, 1))

# Create sequences for LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:(i + seq_length)])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

# Create sequences
seq_length = 12  # Using 12 months of data to predict next month
X, y = create_sequences(values_scaled, seq_length)

# Split data into train and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Create the LSTM model with modified architecture
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),
    Dropout(0.3),  # Increased Dropout to avoid overfitting
    LSTM(50, return_sequences=False),
    Dropout(0.3),
    Dense(25, activation=&#39;relu&#39;),
    Dense(1, activation=&#39;relu&#39;)  # 使用 relu 確保輸出為正數
])

# Compile the model with different optimizer settings
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)

# Train the model with more epochs and validation split
history = model.fit(
    X_train,
    y_train,
    epochs=50,  # Increased epochs for better training
    batch_size=32,
    validation_split=0.1,
    verbose=1
)

# Predict for 2025/1/8
future_date = pd.Timestamp(&#39;2025-07-27&#39;)
last_sequence = values_scaled[-seq_length:]
last_sequence = last_sequence.reshape(1, seq_length, 1)
future_pred_scaled = model.predict(last_sequence)
future_pred = scaler.inverse_transform(future_pred_scaled)

print(f&#39;Predicted value for 2025/1/8: ${future_pred[0][0]:,.2f}&#39;)

# Plot with enhanced date formatting
plt.figure(figsize=(12, 6))
plt.plot(df[&#39;date&#39;], df[&#39;value&#39;], label=&#39;Actual Values&#39;, marker=&#39;o&#39;)
plt.plot(future_date, future_pred[0][0], &#39;r*&#39;, markersize=15, label=&#39;Predicted Value&#39;)

# Format x-axis to show dates in YYYY/MM/DD format
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(&#39;%Y/%m/%d&#39;))
plt.gcf().autofmt_xdate()  # Rotate and align the tick labels

plt.title(&#39;Time Series Prediction&#39;)
plt.xlabel(&#39;Date&#39;)
plt.ylabel(&#39;Value ($)&#39;)
plt.legend()
plt.grid(True)

# Format y-axis to show dollar values
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f&#39;${x:,.2f}&#39;))

print(f&#39;Predicted value for 2025/1/8: ${future_pred[0][0]:,.2f}&#39;)
print(f&#39;Actual value: $369,980.57&#39;)
print(f&#39;Absolute error: ${abs(future_pred[0][0] - 369980.57):,.2f}&#39;)
print(f&#39;Relative error: {abs(future_pred[0][0] - 369980.57)/369980.57*100:.2f}%&#39;)

plt.tight_layout()
plt.show()
</code></pre>
        </div>

        
        <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "s0914712" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
    </div>
  </div>
</section>



<footer class="text-capitalize">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-12 text-center mb-5">
        <a href="https://s0914712.github.io/"><img src="https://s0914712.github.io/images/logo.jpg" alt="chen blog s091sdaf"></a>
      </div>
               
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="tel:0912391259"><i
                class="ti-mobile mr-3 text-primary"></i>0912391259</a></li>
          
                     
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>US, Taiwan</li>
          
                     
          <li class="mb-3"><a class="text-dark" href="mailto:s0914712@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>s0914712@gmail.com</a>
          
          </li>
        </ul>
      </div>
      
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="#">facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="#">twitter</a></li>
          
          <li class="mb-3"><a class="text-dark" href="#">instagram</a></li>
          
          <li class="mb-3"><a class="text-dark" href="#">github</a></li>
          
          <li class="mb-3"><a class="text-dark" href="#">linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/ai%e8%a7%a3%e6%b1%ba%e8%bb%8d%e4%ba%8b%e5%95%8f%e9%a1%8c/">Ai解決軍事問題</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/history-and-taiwan/">History and taiwan</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/html-css/">HTML &amp; css</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/man-over-board-model/">Man over board model</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://s0914712.github.io/about/">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://s0914712.github.io/blog/">Post</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://s0914712.github.io/contact/">Contact</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2021 <a href="https://themefisher.com/hugo-themes/">Chen</a> All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "https://s0914712.github.io/index.json"
</script>

<!-- JS Plugins -->

<script src="https://s0914712.github.io/plugins/jQuery/jquery.min.js"></script>

<script src="https://s0914712.github.io/plugins/bootstrap/bootstrap.min.js"></script>

<script src="https://s0914712.github.io/plugins/slick/slick.min.js"></script>

<script src="https://s0914712.github.io/plugins/venobox/venobox.min.js"></script>

<script src="https://s0914712.github.io/plugins/search/fuse.min.js"></script>

<script src="https://s0914712.github.io/plugins/search/mark.js"></script>

<script src="https://s0914712.github.io/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="https://s0914712.github.io/js/script.min.js"></script>




<script src="https://cdnjs.cloudflare.com/ajax/libs/js-cookie/2.2.1/js.cookie.min.js"></script>
<div id="js-cookie-box" class="cookie-box cookie-box-hide">
	This site uses cookies. By continuing to use this website, you agree to their use. <span id="js-cookie-button" class="btn btn-sm btn-primary ml-2">I Accept</span>
</div>
<script>
	(function ($) {
		const cookieBox = document.getElementById('js-cookie-box');
		const cookieButton = document.getElementById('js-cookie-button');
		if (!Cookies.get('cookie-box')) {
			cookieBox.classList.remove('cookie-box-hide');
			cookieButton.onclick = function () {
				Cookies.set('cookie-box', true, {
					expires:  2 
				});
				cookieBox.classList.add('cookie-box-hide');
			};
		}
	})(jQuery);
</script>


<style>
.cookie-box {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  text-align: center;
  z-index: 9999;
  padding: 1rem 2rem;
  background: rgb(71, 71, 71);
  transition: all .75s cubic-bezier(.19, 1, .22, 1);
  color: #fdfdfd;
}

.cookie-box-hide {
  display: none;
}
</style>
</body>
</html>